{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research data supporting \"A coming of age for many-body methods: Achieving consensus with experiments for CO on MgO\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies our paper: **A coming of age for many-body methods: Achieving consensus with experiments for CO on MgO**. It can be found on GitHub at https://github.com/benshi97/Data_CO_on_MgO and explored interactively on [Colab](https://colab.research.google.com/github/benshi97/Data_CO_on_MgO/blob/main/analyse.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "The adsorption energy of a molecule onto the surface of a material underpins a wide array of applications, spanning heterogeneous catalysis, gas storage and many more. It is the key quantity where experimental measurements and theoretical calculations meet, with agreement being necessary for reliable predictions of reaction rates and mechanisms. The prototypical molecule-surface system is CO adsorbed on MgO, but despite intense scrutiny from theory and experiment, there is still no consensus on its adsorption energy. In particular, the large cost of accurate many-body methods makes reaching converged theoretical estimates difficult, generating a wide range of values. In this work, we address this challenge, leveraging the latest advances in diffusion Monte Carlo (DMC) and coupled cluster theory [CCSD(T)], to obtain accurate predictions for CO on MgO. These reliable theoretical estimates allow us to evaluate the inconsistencies in published temperature programmed desorption experiments, revealing that they arise from variations in employed pre-exponential factors. Using this insight, we derive new experimental estimates of the (electronic) adsorption energy from a more precise pre-exponential factor. With this effort, we are able to reach consensus between multiple theoretical calculations and multiple experiments for the first time. In addition, we show that our recently developed cluster-based CCSD(T) approach provides a low cost route towards achieving accurate adsorption energies. This sets the stage for affordable and reliable theoretical predictions of reaction mechanisms and rates to guide the realization of new catalysts and gas storage materials.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "* [Table S1 and Figure 1 - Past CO on MgO *E*<sub>ads</sub> and Current Work](#tables1fig1)\n",
    "* [Table S2 and S3 - Validating the revPBE-D4 geometry and Computing its $\\Delta_\\textrm{geom}$](#tables2s3)\n",
    "* [Table S4 and S5 - Periodic CCSD(T) Convergence](#tables4)\n",
    "* [Table S6 - Periodic DMC Convergence](#tables6)\n",
    "* [Table S7 - DFT Convergence](#tables7)\n",
    "* [Table S9 to S11 and Figure 2 - SKZCAM Cluster CCSD(T) Convergence](#tables9-s11)\n",
    "* [Table S8 - Final periodic CCSD(T), periodic DMC and cluster CCSD(T) $E_\\textrm{ads}$ and their individual contributions](#tables8)\n",
    "* [Table S12 - Analysis of previous computational work on CO on MgO](#tables12)\n",
    "* [Table S13 - Computation of zero-point energy and thermal contribution terms to convert $H_\\textrm{ads}$ to $E_\\textrm{ads}$](#tables13)\n",
    "* [Figure 3 and S1 - Converting previous experiment $H_\\textrm{ads}$ or $E_\\textrm{act}$ (for TPD) to $E_\\textrm{ads}$](#fig3)\n",
    "* [Table S14 - Final best estimate of TPD experimental adsorption energies](#tables14)\n",
    "* [Table S15 - Effect of CO coverage on $E_\\textrm{ads}$](#tables15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we are in Google Colab environment\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    usetex = False\n",
    "except:\n",
    "    import os\n",
    "    IN_COLAB = False\n",
    "    if os.path.expanduser('~') == '/home/shixubenjamin':\n",
    "        usetex = True\n",
    "    else:\n",
    "        usetex = False\n",
    "\n",
    "# If in Google Colab, install the necessary data and set up the necessary environment\n",
    "if IN_COLAB == True:\n",
    "    !rm -rf /content/Data_CO_on_MgO-main /content/main.zip\n",
    "    !wget https://github.com/benshi97/Data_CO_on_MgO/archive/refs/heads/main.zip\n",
    "    !unzip /content/main.zip\n",
    "    ! apt install ase\n",
    "    !pip install pyblock datetime\n",
    "    %pwd\n",
    "    %cd /content/Data_CO_on_MgO-main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import io\n",
    "from ase.units import mol, kcal, kJ, Hartree\n",
    "import pandas as pd\n",
    "import pyblock\n",
    "from Scripts.jup_plot import *\n",
    "if usetex == True:\n",
    "    textrue_import()\n",
    "else:\n",
    "    texfalse_import()\n",
    "\n",
    "from Scripts.cluster_scripts import *\n",
    "import Scripts.extrapolate as extrapolate\n",
    "\n",
    "\n",
    "# Initialize the dictionary of final adsorption energies and the individual contributions to each adsorption energy\n",
    "ene_final = np.load(\"Data/Misc/methods_eads.npy\", allow_pickle=\"TRUE\").item()\n",
    "\n",
    "# Get the best estimate of the experimental adsorption energies\n",
    "best_expt_eads = np.loadtxt(\"Data/Misc/best_expt.txt\")\n",
    "\n",
    "# List of DFT functionals used in this study\n",
    "dft_functionals = [\n",
    "    \"01_PBE-D2-Ne\",\n",
    "    \"02_revPBE-D4\",\n",
    "    \"03_vdW-DF\",\n",
    "    \"04_rev-vdW-DF2\",\n",
    "    \"05_PBE0-D4\",\n",
    "    \"06_B3LYP-D2-Ne\",\n",
    "]\n",
    "\n",
    "# Some basic conversion factors\n",
    "kcalmol_to_meV = kcal / mol * 1000\n",
    "kjmol_to_meV = kJ / mol * 1000\n",
    "mha_to_meV = Hartree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tables1fig1'></a>\n",
    "## Table S1 and Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of the experimental and theoretical adsorption energies taken or converted from their original literature sources\n",
    "# Experiments go as [Adsorption enthalpy, experiment_type,year,details]\n",
    "experimental_hads = {\n",
    "    'Furuyama et al.': [-3.8*kcalmol_to_meV,'Isothermal adsorption',1978,''],\n",
    "    'Paukshtis et al.': [-15*kjmol_to_meV,'IR spectroscopy',1981,''],\n",
    "    'Henry et al.': [-420,'Auger spectroscopy',1991,''],\n",
    "    'He et al.': [-9.9*kcalmol_to_meV,'Isothermal adsorption',1992,''],\n",
    "    'Wichtendahl et al.': [-140,'Thermal programmed desorption',1999,'Eact, nu=13, low 0.3 ML coverage'],\n",
    "    'Dohnalek et al.': [-18.5*kjmol_to_meV,'Thermal programmed desorption',2001,'Eact, nu=15, low 0.125 ML coverage'],\n",
    "    'Spoto et al.1': [-11*kjmol_to_meV,'FTIR spectroscopy',2003,'MgO smoke'],\n",
    "    'Spoto et al.2': [-12.5*kjmol_to_meV,'FTIR spectroscopy',2004,'MgO smoke'],\n",
    "    'Sterrer et al.': [-15*kjmol_to_meV,'Thermal programmed desorption',2006,'Eact, nu=13, high CO coverage']\n",
    "}\n",
    "\n",
    "# Computation goes as [Adsorption energy, method,year,details]\n",
    "computational_eads = {\n",
    "    'Ugliengo et al.': [-12.7*kjmol_to_meV,'cluster MP2:B3LYP',2002,'HL:LL mechanical embedding'],\n",
    "    'Herschend et al.': [-124,'cluster MP2',2006,'Electrostatic embedding'],\n",
    "    'Qin et al.': [-110,'cluster CISD',2008,'Electrostatic embedding'],\n",
    "    'Staemmler': [-124,'cluster CEPA',2011,'Method of local increments'],\n",
    "    'Boese et al.': [-21*kjmol_to_meV,'cluster MP2+deltaCC:PBE-D2',2013,'HL:LL mechanical embedding'],\n",
    "    'Li et al.': [-3*kjmol_to_meV,'cluster MP2',2015,'Gas phase cluster-in-molecule approach'],\n",
    "    'Bajdich et al.': [-310,'periodic RPA',2015,'Supercell approach'],\n",
    "    'Heuser et al.': [ -15.0*mha_to_meV, 'cluster CC2',2016,'Wave-function frozen-density embedding'],\n",
    "    'Mazheika and Levchenko1': [70,'cluster CCSD(T)',2016,'Electrostatic embedding'],\n",
    "    'Mazheika and Levchenko2': [-10,'cluster RPA',2016,'Electrostatic embedding, RPA+rSE+SOSEX'],\n",
    "    # 'Alessio et al.1': [-21.7*kjmol_to_meV,'cluster MP2+deltaCC:B3LYP-D2',2019,'HL:LL mechanical embedding'],\n",
    "    'Alessio et al.2': [-22.2*kjmol_to_meV,'periodic LMP2+deltaCC',2019,'Supercell with cluster deltaCC'],\n",
    "    'Mitra et al.': [-9.18*kcalmol_to_meV,'periodic CCSD',2022,'Supercell approach']\n",
    "}\n",
    "\n",
    "# Getting the -29 meV thermal correction calculated by DFT and also the RT term\n",
    "thermal_correction = np.genfromtxt('Data/Misc/thermal_corr.txt')[0,0]\n",
    "rt = np.genfromtxt('Data/Misc/thermal_corr.txt')[3,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference</th>\n",
       "      <th>Eads (meV)</th>\n",
       "      <th>Hads (meV)</th>\n",
       "      <th>Method</th>\n",
       "      <th>Year</th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Furuyama et al.</td>\n",
       "      <td>-184</td>\n",
       "      <td>-165</td>\n",
       "      <td>Isothermal adsorption</td>\n",
       "      <td>1978</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paukshtis et al.</td>\n",
       "      <td>-174</td>\n",
       "      <td>-155</td>\n",
       "      <td>IR spectroscopy</td>\n",
       "      <td>1981</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Henry et al.</td>\n",
       "      <td>-439</td>\n",
       "      <td>-420</td>\n",
       "      <td>Auger spectroscopy</td>\n",
       "      <td>1991</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He et al.</td>\n",
       "      <td>-448</td>\n",
       "      <td>-429</td>\n",
       "      <td>Isothermal adsorption</td>\n",
       "      <td>1992</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wichtendahl et al.</td>\n",
       "      <td>-156</td>\n",
       "      <td>-140</td>\n",
       "      <td>Thermal programmed desorption</td>\n",
       "      <td>1999</td>\n",
       "      <td>Eact, nu=13, low 0.3 ML coverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dohnalek et al.</td>\n",
       "      <td>-208</td>\n",
       "      <td>-192</td>\n",
       "      <td>Thermal programmed desorption</td>\n",
       "      <td>2001</td>\n",
       "      <td>Eact, nu=15, low 0.125 ML coverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spoto et al.1</td>\n",
       "      <td>-133</td>\n",
       "      <td>-114</td>\n",
       "      <td>FTIR spectroscopy</td>\n",
       "      <td>2003</td>\n",
       "      <td>MgO smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Spoto et al.2</td>\n",
       "      <td>-148</td>\n",
       "      <td>-130</td>\n",
       "      <td>FTIR spectroscopy</td>\n",
       "      <td>2004</td>\n",
       "      <td>MgO smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sterrer et al.</td>\n",
       "      <td>-172</td>\n",
       "      <td>-155</td>\n",
       "      <td>Thermal programmed desorption</td>\n",
       "      <td>2006</td>\n",
       "      <td>Eact, nu=13, high CO coverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugliengo et al.</td>\n",
       "      <td>-132</td>\n",
       "      <td>-113</td>\n",
       "      <td>cluster MP2:B3LYP</td>\n",
       "      <td>2002</td>\n",
       "      <td>HL:LL mechanical embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Herschend et al.</td>\n",
       "      <td>-124</td>\n",
       "      <td>-105</td>\n",
       "      <td>cluster MP2</td>\n",
       "      <td>2006</td>\n",
       "      <td>Electrostatic embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qin et al.</td>\n",
       "      <td>-110</td>\n",
       "      <td>-91</td>\n",
       "      <td>cluster CISD</td>\n",
       "      <td>2008</td>\n",
       "      <td>Electrostatic embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staemmler</td>\n",
       "      <td>-124</td>\n",
       "      <td>-105</td>\n",
       "      <td>cluster CEPA</td>\n",
       "      <td>2011</td>\n",
       "      <td>Method of local increments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boese et al.</td>\n",
       "      <td>-218</td>\n",
       "      <td>-199</td>\n",
       "      <td>cluster MP2+deltaCC:PBE-D2</td>\n",
       "      <td>2013</td>\n",
       "      <td>HL:LL mechanical embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Li et al.</td>\n",
       "      <td>-31</td>\n",
       "      <td>-12</td>\n",
       "      <td>cluster MP2</td>\n",
       "      <td>2015</td>\n",
       "      <td>Gas phase cluster-in-molecule approach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bajdich et al.</td>\n",
       "      <td>-310</td>\n",
       "      <td>-291</td>\n",
       "      <td>periodic RPA</td>\n",
       "      <td>2015</td>\n",
       "      <td>Supercell approach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Heuser et al.</td>\n",
       "      <td>-408</td>\n",
       "      <td>-389</td>\n",
       "      <td>cluster CC2</td>\n",
       "      <td>2016</td>\n",
       "      <td>Wave-function frozen-density embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mazheika and Levchenko1</td>\n",
       "      <td>70</td>\n",
       "      <td>89</td>\n",
       "      <td>cluster CCSD(T)</td>\n",
       "      <td>2016</td>\n",
       "      <td>Electrostatic embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mazheika and Levchenko2</td>\n",
       "      <td>-10</td>\n",
       "      <td>9</td>\n",
       "      <td>cluster RPA</td>\n",
       "      <td>2016</td>\n",
       "      <td>Electrostatic embedding, RPA+rSE+SOSEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alessio et al.2</td>\n",
       "      <td>-230</td>\n",
       "      <td>-211</td>\n",
       "      <td>periodic LMP2+deltaCC</td>\n",
       "      <td>2019</td>\n",
       "      <td>Supercell with cluster deltaCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mitra et al.</td>\n",
       "      <td>-398</td>\n",
       "      <td>-379</td>\n",
       "      <td>periodic CCSD</td>\n",
       "      <td>2022</td>\n",
       "      <td>Supercell approach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Reference  Eads (meV)  Hads (meV)  \\\n",
       "0           Furuyama et al.        -184        -165   \n",
       "1          Paukshtis et al.        -174        -155   \n",
       "2              Henry et al.        -439        -420   \n",
       "3                 He et al.        -448        -429   \n",
       "4        Wichtendahl et al.        -156        -140   \n",
       "5           Dohnalek et al.        -208        -192   \n",
       "6             Spoto et al.1        -133        -114   \n",
       "7             Spoto et al.2        -148        -130   \n",
       "8            Sterrer et al.        -172        -155   \n",
       "0           Ugliengo et al.        -132        -113   \n",
       "1          Herschend et al.        -124        -105   \n",
       "2                Qin et al.        -110         -91   \n",
       "3                 Staemmler        -124        -105   \n",
       "4              Boese et al.        -218        -199   \n",
       "5                 Li et al.         -31         -12   \n",
       "6            Bajdich et al.        -310        -291   \n",
       "7             Heuser et al.        -408        -389   \n",
       "8   Mazheika and Levchenko1          70          89   \n",
       "9   Mazheika and Levchenko2         -10           9   \n",
       "10          Alessio et al.2        -230        -211   \n",
       "11             Mitra et al.        -398        -379   \n",
       "\n",
       "                           Method  Year  \\\n",
       "0           Isothermal adsorption  1978   \n",
       "1                 IR spectroscopy  1981   \n",
       "2              Auger spectroscopy  1991   \n",
       "3           Isothermal adsorption  1992   \n",
       "4   Thermal programmed desorption  1999   \n",
       "5   Thermal programmed desorption  2001   \n",
       "6               FTIR spectroscopy  2003   \n",
       "7               FTIR spectroscopy  2004   \n",
       "8   Thermal programmed desorption  2006   \n",
       "0               cluster MP2:B3LYP  2002   \n",
       "1                     cluster MP2  2006   \n",
       "2                    cluster CISD  2008   \n",
       "3                    cluster CEPA  2011   \n",
       "4      cluster MP2+deltaCC:PBE-D2  2013   \n",
       "5                     cluster MP2  2015   \n",
       "6                    periodic RPA  2015   \n",
       "7                     cluster CC2  2016   \n",
       "8                 cluster CCSD(T)  2016   \n",
       "9                     cluster RPA  2016   \n",
       "10          periodic LMP2+deltaCC  2019   \n",
       "11                  periodic CCSD  2022   \n",
       "\n",
       "                                   Details  \n",
       "0                                           \n",
       "1                                           \n",
       "2                                           \n",
       "3                                           \n",
       "4         Eact, nu=13, low 0.3 ML coverage  \n",
       "5       Eact, nu=15, low 0.125 ML coverage  \n",
       "6                                MgO smoke  \n",
       "7                                MgO smoke  \n",
       "8            Eact, nu=13, high CO coverage  \n",
       "0               HL:LL mechanical embedding  \n",
       "1                  Electrostatic embedding  \n",
       "2                  Electrostatic embedding  \n",
       "3               Method of local increments  \n",
       "4               HL:LL mechanical embedding  \n",
       "5   Gas phase cluster-in-molecule approach  \n",
       "6                       Supercell approach  \n",
       "7   Wave-function frozen-density embedding  \n",
       "8                  Electrostatic embedding  \n",
       "9   Electrostatic embedding, RPA+rSE+SOSEX  \n",
       "10          Supercell with cluster deltaCC  \n",
       "11                      Supercell approach  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the experimental and computational adsorption energies into a dataframe\n",
    "df = pd.DataFrame(experimental_hads).T\n",
    "df = df.reset_index()\n",
    "df.columns = ['Reference','Hads (meV)','Method','Year','Details']\n",
    "df['Hads (meV)'] = df['Hads (meV)'].apply(lambda x: round(x))\n",
    "\n",
    "eads_list = []\n",
    "for i in experimental_hads:\n",
    "    if 'desorption' in experimental_hads[i][1]:\n",
    "        eads_list += [experimental_hads[i][0] - thermal_correction + 0.5*rt]\n",
    "    else:\n",
    "        eads_list += [experimental_hads[i][0] - thermal_correction]\n",
    "\n",
    "\n",
    "df['Eads (meV)'] = eads_list\n",
    "df['Eads (meV)'] = df['Eads (meV)'].round().astype(int)\n",
    "\n",
    "# df['Hads (meV)'] - thermal_correction\n",
    "# df['Details'] = pd.Series(dtype='str')\n",
    "df = df[['Reference','Eads (meV)','Hads (meV)','Method','Year','Details']]\n",
    "\n",
    "df1 = pd.DataFrame(computational_eads).T\n",
    "df1 = df1.reset_index()\n",
    "df1.columns = ['Reference','Eads (meV)','Method','Year','Details']\n",
    "df1['Eads (meV)'] = df1['Eads (meV)'].apply(lambda x: round(x))\n",
    "df1['Hads (meV)'] = df1['Eads (meV)'] + thermal_correction\n",
    "df1['Hads (meV)'] = df1['Hads (meV)'].apply(lambda x: round(x))\n",
    "\n",
    "df1 = df1[['Reference','Eads (meV)','Hads (meV)','Method','Year','Details']]\n",
    "df1\n",
    "\n",
    "df_final = pd.concat([df,df1])\n",
    "# df_final.to_clipboard( index=False, excel=True,sep=',')\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shixubenjamin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: UserWarning: You passed a edgecolor/edgecolors ('none') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n"
     ]
    }
   ],
   "source": [
    "# List to store experimental energies and times\n",
    "exp_energies = []\n",
    "exp_time = []\n",
    "\n",
    "# Loop through different experimental sources\n",
    "for i in ['Wichtendahl et al.','Dohnalek et al.','Spoto et al.1','Spoto et al.2','Sterrer et al.']:\n",
    "    if 'desorption' in experimental_hads[i][1]:\n",
    "        exp_energies += [experimental_hads[i][0] - thermal_correction - 2.5]\n",
    "    else:\n",
    "        exp_energies += [experimental_hads[i][0] - thermal_correction]\n",
    "    exp_time += [experimental_hads[i][2]]\n",
    "\n",
    "\n",
    "# Separate computational data based on approach type (cluster or periodic)\n",
    "cwft_cluster_time = [computational_eads[x][2] for x in computational_eads if 'cluster' in computational_eads[x][1]]\n",
    "cwft_cluster_energies = [computational_eads[x][0] for x in computational_eads if 'cluster' in computational_eads[x][1]]\n",
    "\n",
    "cwft_periodic_time = [computational_eads[x][2] for x in computational_eads if 'periodic' in computational_eads[x][1]]\n",
    "cwft_periodic_energies = [computational_eads[x][0] for x in computational_eads if 'periodic' in computational_eads[x][1]]\n",
    "\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, axs = plt.subplots(figsize=(6.66,3),dpi=1200, sharey=True,constrained_layout=True)\n",
    "\n",
    "# Arrow properties\n",
    "prop = dict(arrowstyle=\"->,head_width=0.1,head_length=0.2\",\n",
    "            shrinkA=0,shrinkB=0)\n",
    "\n",
    "# Scatter plot for different data points\n",
    "axs.scatter(cwft_cluster_time,cwft_cluster_energies,marker=\"x\",color=color_dict['orange'],edgecolors='none',label='Theory: Cluster approach')\n",
    "axs.scatter(cwft_periodic_time,cwft_periodic_energies,marker=\"o\",color=color_dict['teal'],facecolor='none',label='Theory: Periodic approach')\n",
    "axs.scatter(exp_time,exp_energies,marker=\"^\",color=color_dict['grey'],facecolor='none',label='Experiment')\n",
    "\n",
    "if usetex == True:\n",
    "    # Annotate experimental data points with labels\n",
    "    for index, i in enumerate(exp_time):\n",
    "        if i == 1999:\n",
    "            axs.annotate(\"TPD\" + r'\\textsuperscript{l}',xy=(1999,exp_energies[index]-15), xytext=(1999,exp_energies[index]-80),arrowprops=prop,ha='center',fontsize=8)    \n",
    "        if i == 2001:\n",
    "            axs.annotate(\"TPD\" + r'\\textsuperscript{m}',xy=(i,exp_energies[index]-15), xytext=(i,exp_energies[index]-40),arrowprops=prop,ha='center',fontsize=8)   \n",
    "        if i == 2006:\n",
    "            axs.annotate(\"TPD\" + r'\\textsuperscript{p}',xy=(i,exp_energies[index]-15), xytext=(i,exp_energies[index]-60),arrowprops=prop,ha='center',fontsize=8)\n",
    "        if i == 2003:\n",
    "            axs.annotate(\"FTIR\" + r'\\textsuperscript{n,o}',xy=(i,exp_energies[index]-15), xytext=(i+0.5,exp_energies[index]-60),arrowprops=prop,ha='center',fontsize=8)\n",
    "        if i == 2004:\n",
    "            axs.annotate('',xy=(i,exp_energies[index]-15), xytext=(i-0.5,exp_energies[index]-40),arrowprops=prop,ha='center',fontsize=8)\n",
    "\n",
    "    # Annotations for computational data\n",
    "    for i in ['Ugliengo et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) + r'\\textsuperscript{a}',xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0] + 80),arrowprops=prop,ha='center',fontsize=8)\n",
    "\n",
    "    for i in ['Herschend et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) + r'\\textsuperscript{b}',xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0] + 80),arrowprops=prop,ha='center',fontsize=8)\n",
    "\n",
    "    for i in ['Staemmler']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) + r'\\textsuperscript{d}',xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0] + 80),arrowprops=prop,ha='center',fontsize=8)\n",
    "\n",
    "    for i in ['Qin et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) + r'\\textsuperscript{c}',xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0] + 100),arrowprops=prop,ha='center',fontsize=8)\n",
    "\n",
    "    for i in ['Mitra et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1])+ r'\\textsuperscript{k}',xy=(computational_eads[i][2]-0.5,computational_eads[i][0]), xytext=(computational_eads[i][2]-4,computational_eads[i][0]),arrowprops=prop,ha='left',fontsize=8)\n",
    "\n",
    "    for i in ['Heuser et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) + r'\\textsuperscript{i}',xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0]+55),arrowprops=prop,ha='left',fontsize=8)\n",
    "\n",
    "    for i in ['Bajdich et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) + r'\\textsuperscript{g}',xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0]+55),arrowprops=prop,ha='left',fontsize=8)\n",
    "\n",
    "    for i in ['Mazheika and Levchenko1']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1])+ r'\\textsuperscript{j}',xy=(computational_eads[i][2]-0.5,computational_eads[i][0]), xytext=(computational_eads[i][2]-5,computational_eads[i][0]),arrowprops=prop,ha='left',fontsize=8)\n",
    "\n",
    "    for i in ['Mazheika and Levchenko2']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1])+ r'\\textsuperscript{j}',xy=(computational_eads[i][2]-0.5,computational_eads[i][0]), xytext=(computational_eads[i][2]-5,computational_eads[i][0]),arrowprops=prop,ha='left',fontsize=8)\n",
    "\n",
    "    for i in ['Li et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) +  r'\\textsuperscript{h}',xy=(computational_eads[i][2]+0.5,computational_eads[i][0]), xytext=(computational_eads[i][2]+2,computational_eads[i][0]),arrowprops=prop,ha='left',fontsize=8)\n",
    "\n",
    "    # for i in ['Alessio et al.1']:\n",
    "    #     axs.annotate(r'MP2+$\\Delta$CC:B3LYP-D2[Ne]'  + r'\\textsuperscript{f}',xy=(computational_eads[i][2],computational_eads[i][0]), xytext=(computational_eads[i][2],computational_eads[i][0]+65),arrowprops=prop,ha='center',fontsize=8)\n",
    "\n",
    "    for i in ['Alessio et al.2']:\n",
    "        axs.annotate(r'LMP2+$\\Delta$CC'.format(computational_eads[i][1]) + r'\\textsuperscript{f}',xy=(computational_eads[i][2],computational_eads[i][0]-15), xytext=(computational_eads[i][2],computational_eads[i][0]-80),arrowprops=prop,ha='left',fontsize=8)\n",
    "        axs.errorbar(computational_eads[i][2],computational_eads[i][0],yerr=0.3*kjmol_to_meV,fmt='o',markersize=0,capsize=3,color=color_dict['teal'],markerfacecolor='none',alpha=0.5)\n",
    "\n",
    "    for i in ['Boese et al.']:\n",
    "        axs.annotate(r'MP2+$\\Delta$CC:PBE-D2[Ne]'  + r'\\textsuperscript{e}',xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0]+60),arrowprops=prop,ha='center',fontsize=8)\n",
    "        axs.errorbar(computational_eads[i][2],computational_eads[i][0],yerr=1.0*kjmol_to_meV,fmt='^',markersize=0,capsize=3,color=color_dict['orange'],markerfacecolor='none',alpha=0.5)\n",
    "\n",
    "    # Error bars for specific data points coming from this work\n",
    "    axs.errorbar(2025,ene_final['Cluster CCSD(T)']['Final'][0],yerr=ene_final['Cluster CCSD(T)']['Final'][1],fmt='x',markersize=0,capsize=3,color=color_dict['red'],markerfacecolor='none',alpha=0.5) #,label='SKZCAM-CCSD(T)')\n",
    "    axs.errorbar(2029,ene_final['Periodic CCSD(T)']['Final'][0],yerr=ene_final['Periodic CCSD(T)']['Final'][1],fmt='o',markersize=0,capsize=3,color=color_dict['green'],markerfacecolor='none',alpha=0.5) #,label='p-CCSD(T)')\n",
    "    axs.errorbar(2033,ene_final['Periodic DMC']['Final'][0],yerr=ene_final['Periodic DMC']['Final'][1],fmt='o',markersize=0,capsize=3,color=color_dict['blue'],markerfacecolor='none',alpha=0.5) #,label='p-DMC')\n",
    "    axs.errorbar(2037,best_expt_eads[0],yerr=best_expt_eads[1],fmt='^',markersize=0,capsize=3,color=color_dict['grey'],markerfacecolor='none',alpha=0.5) #,label='p-DMC')\n",
    "\n",
    "\n",
    "    axs.scatter(2025,ene_final['Cluster CCSD(T)']['Final'][0],marker='x',s=50,color=color_dict['red'])\n",
    "    axs.scatter(2029,ene_final['Periodic CCSD(T)']['Final'][0],marker='o',s=50,color=color_dict['green'],facecolor='none')\n",
    "    axs.scatter(2033,ene_final['Periodic DMC']['Final'][0],marker='o',s=50,color=color_dict['blue'],facecolor='none')\n",
    "    axs.scatter(2037,best_expt_eads[0],marker='^',s=50,color=color_dict['grey'],facecolor='none')\n",
    "\n",
    "    axs.spines[[ 'top']].set_visible(False)\n",
    "\n",
    "    axs.yaxis.set_ticks_position('both')\n",
    "\n",
    "    axs.legend(loc=(0.1,0.75),frameon=True,fontsize=8)\n",
    "else:\n",
    "    # Same annotations but for non-TeX mode in Google Colab\n",
    "    for index, i in enumerate(exp_time):\n",
    "        if i == 1999:\n",
    "            axs.annotate(\"TPD\" ,xy=(1999,exp_energies[index]-15), xytext=(1999,exp_energies[index]-80),arrowprops=prop,ha='center',fontsize=8)    \n",
    "        if i == 2001:\n",
    "            axs.annotate(\"TPD\" ,xy=(i,exp_energies[index]-15), xytext=(i,exp_energies[index]-40),arrowprops=prop,ha='center',fontsize=8)   \n",
    "        if i == 2006:\n",
    "            axs.annotate(\"TPD\" ,xy=(i,exp_energies[index]-15), xytext=(i,exp_energies[index]-60),arrowprops=prop,ha='center',fontsize=8)\n",
    "        if i == 2003:\n",
    "            axs.annotate(\"FTIR\" ,xy=(i,exp_energies[index]-15), xytext=(i+0.5,exp_energies[index]-60),arrowprops=prop,ha='center',fontsize=8)\n",
    "        if i == 2004:\n",
    "            axs.annotate('',xy=(i,exp_energies[index]-15), xytext=(i-0.5,exp_energies[index]-40),arrowprops=prop,ha='center',fontsize=8)\n",
    "\n",
    "\n",
    "    for i in ['Ugliengo et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) ,xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0] + 80),arrowprops=prop,ha='center',fontsize=8)\n",
    "\n",
    "    for i in ['Herschend et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) ,xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0] + 80),arrowprops=prop,ha='center',fontsize=8)\n",
    "\n",
    "    for i in ['Staemmler']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) ,xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0] + 80),arrowprops=prop,ha='center',fontsize=8)\n",
    "\n",
    "    for i in ['Qin et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) ,xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0] + 100),arrowprops=prop,ha='center',fontsize=8)\n",
    "\n",
    "    for i in ['Mitra et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]),xy=(computational_eads[i][2]-0.5,computational_eads[i][0]), xytext=(computational_eads[i][2]-4,computational_eads[i][0]),arrowprops=prop,ha='left',fontsize=8)\n",
    "\n",
    "    for i in ['Heuser et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) ,xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0]+55),arrowprops=prop,ha='left',fontsize=8)\n",
    "\n",
    "    for i in ['Bajdich et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) ,xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0]+55),arrowprops=prop,ha='left',fontsize=8)\n",
    "\n",
    "    for i in ['Mazheika and Levchenko1']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]),xy=(computational_eads[i][2]-0.5,computational_eads[i][0]), xytext=(computational_eads[i][2]-5,computational_eads[i][0]),arrowprops=prop,ha='left',fontsize=8)\n",
    "\n",
    "    for i in ['Mazheika and Levchenko2']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]),xy=(computational_eads[i][2]-0.5,computational_eads[i][0]), xytext=(computational_eads[i][2]-5,computational_eads[i][0]),arrowprops=prop,ha='left',fontsize=8)\n",
    "\n",
    "    for i in ['Li et al.']:\n",
    "        axs.annotate(\"{0}\".format(computational_eads[i][1].split()[1]) ,xy=(computational_eads[i][2]+0.5,computational_eads[i][0]), xytext=(computational_eads[i][2]+2,computational_eads[i][0]),arrowprops=prop,ha='left',fontsize=8)\n",
    "\n",
    "    # for i in ['Alessio et al.1']:\n",
    "    #     axs.annotate(r'MP2+$\\Delta$CC:B3LYP-D2[Ne]'  + r'\\textsuperscript{f}',xy=(computational_eads[i][2],computational_eads[i][0]), xytext=(computational_eads[i][2],computational_eads[i][0]+65),arrowprops=prop,ha='center',fontsize=8)\n",
    "\n",
    "    for i in ['Alessio et al.2']:\n",
    "        axs.annotate(r'LMP2+$\\Delta$CC'.format(computational_eads[i][1]),xy=(computational_eads[i][2],computational_eads[i][0]-15), xytext=(computational_eads[i][2],computational_eads[i][0]-80),arrowprops=prop,ha='left',fontsize=8)\n",
    "        axs.errorbar(computational_eads[i][2],computational_eads[i][0],yerr=0.3*kjmol_to_meV,fmt='o',markersize=0,capsize=3,color=color_dict['teal'],markerfacecolor='none',alpha=0.5)\n",
    "\n",
    "    for i in ['Boese et al.']:\n",
    "        axs.annotate(r'MP2+$\\Delta$CC:PBE-D2[Ne]',xy=(computational_eads[i][2],computational_eads[i][0]+15), xytext=(computational_eads[i][2],computational_eads[i][0]+60),arrowprops=prop,ha='center',fontsize=8)\n",
    "        axs.errorbar(computational_eads[i][2],computational_eads[i][0],yerr=1.0*kjmol_to_meV,fmt='^',markersize=0,capsize=3,color=color_dict['orange'],markerfacecolor='none',alpha=0.5)\n",
    "\n",
    "\n",
    "    axs.errorbar(2025,ene_final['Cluster CCSD(T)']['Final'][0],yerr=ene_final['Cluster CCSD(T)']['Final'][1],fmt='x',markersize=0,capsize=3,color=color_dict['red'],markerfacecolor='none',alpha=0.5)\n",
    "    axs.errorbar(2029,ene_final['Periodic CCSD(T)']['Final'][0],yerr=ene_final['Periodic CCSD(T)']['Final'][1],fmt='o',markersize=0,capsize=3,color=color_dict['green'],markerfacecolor='none',alpha=0.5)\n",
    "    axs.errorbar(2033,ene_final['Periodic DMC']['Final'][0],yerr=ene_final['Periodic DMC']['Final'][1],fmt='o',markersize=0,capsize=3,color=color_dict['blue'],markerfacecolor='none',alpha=0.5)\n",
    "    axs.errorbar(2037,best_expt_eads[0],yerr=best_expt_eads[1],fmt='^',markersize=0,capsize=3,color=color_dict['grey'],markerfacecolor='none',alpha=0.5)\n",
    "\n",
    "\n",
    "    axs.scatter(2025,ene_final['Cluster CCSD(T)']['Final'][0],marker='x',s=50,color=color_dict['red'],label='Cluster CCSD(T)')\n",
    "    axs.scatter(2029,ene_final['Periodic CCSD(T)']['Final'][0],marker='o',s=50,color=color_dict['green'],facecolor='none' ,label='Periodic CCSD(T)')\n",
    "    axs.scatter(2033,ene_final['Periodic DMC']['Final'][0],marker='o',s=50,color=color_dict['blue'],facecolor='none',label='Periodic DMC')\n",
    "    axs.scatter(2037,best_expt_eads[0],marker='^',s=50,color=color_dict['grey'],facecolor='none',label='Best Experiment')\n",
    "    axs.spines[[ 'top']].set_visible(False)\n",
    "    axs.yaxis.set_ticks_position('both')\n",
    "    axs.legend(loc='upper right',frameon=True,fontsize=8)\n",
    "\n",
    "\n",
    "# Additional plot settings\n",
    "axs.set_xlim([1997,2039])\n",
    "axs.set_xticks([2000,2005,2010,2015,2020])\n",
    "axs.set_ylim([100,-500])\n",
    "if usetex == True:\n",
    "    axs.set_ylabel(r'Adsorption energy $E_\\textrm{ads}$ (meV)')\n",
    "else:\n",
    "    axs.set_ylabel('Adsorption energy (meV)')\n",
    "\n",
    "\n",
    "plt.savefig('Figures/Fig_01.png') # Save the figure\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tables2s3'></a>\n",
    "## Table S2 and S3 - Validating the revPBE-D4 geometry and Computing its $\\Delta_\\textrm{geom}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Eads_True  Eads_Approx  Difference\n",
      "01_PBE-D2-Ne         -228         -225          -4\n",
      "02_revPBE-D4         -207         -207           0\n",
      "03_vdW-DF            -232         -212         -20\n",
      "04_rev-vdW-DF2       -266         -265          -1\n",
      "05_PBE0-D4           -234         -241           7\n",
      "06_B3LYP-D2-Ne       -149         -148          -1\n",
      "RMSD: 10\n"
     ]
    }
   ],
   "source": [
    "# Getting DeltaGeom for Table S3\n",
    "\n",
    "# List of DFT functional names\n",
    "dft_functionals = ['01_PBE-D2-Ne', '02_revPBE-D4', '03_vdW-DF', '04_rev-vdW-DF2', '05_PBE0-D4', '06_B3LYP-D2-Ne']\n",
    "\n",
    "# Dictionary to store adsorption energies for true and approximate cases\n",
    "ene_ads_list = {'Eads_True': {x: 0 for x in dft_functionals},\n",
    "                'Eads_Approx': {x: 0 for x in dft_functionals}}\n",
    "\n",
    "# Calculate the relaxation energy difference for a specific functional\n",
    "for i in ['02_revPBE-D4']:\n",
    "    # Obtain energies using the 'find_energy' function\n",
    "    ad_slab = find_energy('Data/DFT/Eads/{0}/AD_SLAB/OUTCAR'.format(i), code_format='vasp')\n",
    "    ad = find_energy('Data/DFT/Eads/{0}/AD/OUTCAR'.format(i), code_format='vasp')\n",
    "    slab = find_energy('Data/DFT/Eads/{0}/SLAB/OUTCAR'.format(i), code_format='vasp')\n",
    "    ad_fs = find_energy('Data/DFT/Eint/{0}/SLAB_FS/OUTCAR'.format(i), code_format='vasp')\n",
    "    slab_fs = find_energy('Data/DFT/Eint/{0}/AD_FS/OUTCAR'.format(i), code_format='vasp')\n",
    "    ad_slab_fs = find_energy('Data/DFT/Eint/{0}/AD_SLAB/OUTCAR'.format(i), code_format='vasp')\n",
    "    e_relax = (slab_fs - slab) + (ad_fs - ad)\n",
    "\n",
    "# Initialize a variable to store the squared sum of differences\n",
    "squared_sum = 0\n",
    "\n",
    "# Calculate adsorption energies and predictions for all DFT functionals\n",
    "for i in dft_functionals:\n",
    "    # Obtain energies using the 'find_energy' function\n",
    "    ad_slab = find_energy('Data/DFT/Eads/{0}/AD_SLAB/OUTCAR'.format(i), code_format='vasp')\n",
    "    ad = find_energy('Data/DFT/Eads/{0}/AD/OUTCAR'.format(i), code_format='vasp')\n",
    "    slab = find_energy('Data/DFT/Eads/{0}/SLAB/OUTCAR'.format(i), code_format='vasp')\n",
    "    ad_fs = find_energy('Data/DFT/Eint/{0}/SLAB_FS/OUTCAR'.format(i), code_format='vasp')\n",
    "    slab_fs = find_energy('Data/DFT/Eint/{0}/AD_FS/OUTCAR'.format(i), code_format='vasp')\n",
    "    ad_slab_fs = find_energy('Data/DFT/Eint/{0}/AD_SLAB/OUTCAR'.format(i), code_format='vasp')\n",
    "    \n",
    "    # Calculate various energy terms and convert to millielectronvolts (meV)\n",
    "    eads = (ad_slab - ad - slab) * 1000\n",
    "    eint = (ad_slab_fs - slab_fs - ad_fs) * 1000\n",
    "    eads_pred = (ad_slab_fs - slab_fs - ad_fs + e_relax) * 1000\n",
    "    \n",
    "    # Store calculated energies in the dictionary\n",
    "    ene_ads_list['Eads_True'][i] = eads\n",
    "    ene_ads_list['Eads_Approx'][i] = eads_pred\n",
    "    \n",
    "    # Calculate squared differences and update squared_sum\n",
    "    squared_sum += (eads - eads_pred) ** 2\n",
    "\n",
    "# Create a DataFrame from the ene_ads_list dictionary\n",
    "df = pd.DataFrame(ene_ads_list)\n",
    "\n",
    "# Calculate and add the 'Difference' column to the DataFrame\n",
    "df['Difference'] = df['Eads_True'] - df['Eads_Approx']\n",
    "\n",
    "# Round the DataFrame values and convert to integers\n",
    "df = df.round().astype(int)\n",
    "\n",
    "# Print the DataFrame and RMSD\n",
    "print(df)\n",
    "print('RMSD:', round(np.sqrt(squared_sum / 5)))\n",
    "\n",
    "# Calculate the delta geom values and store in a list\n",
    "delta_geom = [e_relax * 1000, np.sqrt(squared_sum / 5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the reference bond length from CCSD(T) calculations for Table S2\n",
    "\n",
    "# Dictionary to store calculated bond energies for various methods and functionals\n",
    "energy_bond_length = {\"CCSD(T)_small\": [],\n",
    "                    \"MP2_small\": [],\n",
    "                    \"MP2_large\": [],\n",
    "                    \"CCSD(T) final\": [],\n",
    "                    \"01_PBE-D2-Ne\": [],\n",
    "                    \"02_revPBE-D4\": [],\n",
    "                    \"03_vdW-DF\": [],\n",
    "                    \"04_rev-vdW-DF2\": [],\n",
    "                    \"05_PBE0-D4\": [],\n",
    "                    \"06_B3LYP-D2-Ne\": []}\n",
    "\n",
    "# List of bond lengths\n",
    "r_list = ['2.36','2.38','2.40','2.41','2.42','2.43','2.44','2.45','2.46','2.47','2.48','2.49','2.50','2.51','2.52','2.53','2.54','2.55','2.56','2.57','2.58','2.60','2.62']\n",
    "\n",
    "# Loop through each bond length\n",
    "for j in r_list:\n",
    "    # Initialize lists to store energy values for different methods\n",
    "    ene_hf_small = []\n",
    "    ene_hf_large = []\n",
    "    ene_mp2_small = []\n",
    "    ene_mp2_large = []\n",
    "    ene_cc_small = []\n",
    "    \n",
    "    # Loop through different basis sets\n",
    "    for k in ['TZ', 'QZ']:\n",
    "        # Collect energies using different methods and basis sets\n",
    "        ene_hf_small += [get_eads('Data/CC_Convergence/Bond_Dist/{0}/CC/{1}'.format(j, k), code_format='mrcc', typ='hf')]\n",
    "        ene_mp2_small += [get_eads('Data/CC_Convergence/Bond_Dist/{0}/CC/{1}'.format(j, k), code_format='mrcc', typ='mp2')]\n",
    "        ene_cc_small += [get_eads('Data/CC_Convergence/Bond_Dist/{0}/CC/{1}'.format(j, k), code_format='mrcc', typ='ccsdt')]\n",
    "        ene_hf_large += [get_eads('Data/CC_Convergence/Bond_Dist/{0}/MP2/{1}'.format(j, k), code_format='mrcc', typ='hf')]\n",
    "        ene_mp2_large += [get_eads('Data/CC_Convergence/Bond_Dist/{0}/MP2/{1}'.format(j, k), code_format='mrcc', typ='lmp2_corr')]\n",
    "\n",
    "    # Extrapolate energies and store in the energy_bond_length dictionary\n",
    "    energy_bond_length['CCSD(T)_small'] += [(extrapolate.get_cbs(ene_hf_small[0], ene_cc_small[0], ene_hf_small[1], ene_cc_small[1], X=3, Y=4, family='mixcc', output=False))[-1] * Hartree * 1000]\n",
    "    energy_bond_length['MP2_small'] += [(extrapolate.get_cbs(ene_hf_small[0], ene_mp2_small[0], ene_hf_small[1], ene_mp2_small[1], X=3, Y=4, family='mixcc', output=False))[-1] * Hartree * 1000]\n",
    "    energy_bond_length['MP2_large'] += [(extrapolate.get_cbs(ene_hf_large[0], ene_mp2_large[0], ene_hf_large[1], ene_mp2_large[1], X=3, Y=4, family='mixcc', output=False))[-1] * Hartree * 1000]\n",
    "    energy_bond_length['CCSD(T) final'] += [energy_bond_length['MP2_large'][-1] + energy_bond_length['CCSD(T)_small'][-1] - energy_bond_length['MP2_small'][-1]]\n",
    "\n",
    "    # Loop through DFT functionals and collect energies\n",
    "    for k in dft_functionals:\n",
    "        energy_bond_length[k] += [find_energy('Data/DFT/Bond_Dist/{0}/{1}/OUTCAR'.format(k, j), code_format='vasp')]\n",
    "\n",
    "# Dictionary to store calculated magnesium-carbon (Mg-C) bond lengths\n",
    "mg_c_bond_length = {\n",
    "    \"CCSD(T) final\": 0,\n",
    "    \"01_PBE-D2-Ne\": 0,\n",
    "    \"02_revPBE-D4\": 0,\n",
    "    \"03_vdW-DF\": 0,\n",
    "    \"04_rev-vdW-DF2\": 0,\n",
    "    \"05_PBE0-D4\": 0,\n",
    "    \"06_B3LYP-D2-Ne\": 0\n",
    "}\n",
    "\n",
    "# Loop through the methods in the mg_c_bond_length dictionary\n",
    "for i in mg_c_bond_length:\n",
    "    # Find the index with the minimum energy for the given method\n",
    "    min_idx = np.argmin(energy_bond_length[i])\n",
    "    # Fit a quadratic polynomial to the energy values around the minimum\n",
    "    a = np.polyfit([float(x) for x in r_list[min_idx - 3: min_idx + 3]], energy_bond_length[i][min_idx - 3: min_idx + 3], deg=2)\n",
    "    # Calculate the bond length using the extremum of the fitted quadratic\n",
    "    mg_c_bond_length[i] = -a[1] / (2 * a[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Eads_True  Lattice Parameter  Mg -- C distance\n",
      "01_PBE-D2-Ne         -228              4.234             2.421\n",
      "02_revPBE-D4         -207              4.220             2.460\n",
      "03_vdW-DF            -232              4.273             2.544\n",
      "04_rev-vdW-DF2       -266              4.220             2.413\n",
      "05_PBE0-D4           -234              4.175             2.460\n",
      "06_B3LYP-D2-Ne       -149              4.202             2.512\n",
      "Reference            -199              4.217             2.508\n"
     ]
    }
   ],
   "source": [
    "# Getting the lattice parameters for Table S2\n",
    "\n",
    "# Initialize an empty list to store lattice parameters for each DFT functional\n",
    "latpar_functional = []\n",
    "\n",
    "# Loop through each DFT functional\n",
    "for i in dft_functionals:\n",
    "    # Read the CONTCAR file to obtain lattice parameter 'a'\n",
    "    a = io.read('Data/DFT/Unit_Cell/{0}/CONTCAR'.format(i))\n",
    "    # Add the lattice parameter 'a' to the latpar_functional list\n",
    "    latpar_functional += [a.get_cell()[0][0]]\n",
    "\n",
    "# Create a list of Mg-C bond lengths corresponding to the DFT functionals\n",
    "bond_length = [mg_c_bond_length[x] for x in dft_functionals]\n",
    "\n",
    "# Add the lattice parameter and Mg-C bond distance information to the DataFrame 'df'\n",
    "df['Lattice Parameter'] = [round(x, 3) for x in latpar_functional]\n",
    "df['Mg -- C distance'] = [round(x, 3) for x in bond_length]\n",
    "\n",
    "# Create a new DataFrame 'df1' by dropping unnecessary columns from 'df'\n",
    "df1 = df.drop(['Eads_Approx', 'Difference'], axis=1)\n",
    "\n",
    "# Create a new row containing reference data\n",
    "new_row = {'Eads_True': int(round(ene_final['Cluster CCSD(T)']['Final'][0])),\n",
    "           'Lattice Parameter': 4.217,  # Experimental reference lattice parameter\n",
    "           'Mg -- C distance': round(mg_c_bond_length['CCSD(T) final'], 3)}\n",
    "\n",
    "# Append the reference row to 'df1' to create a new DataFrame 'df2'\n",
    "df2 = df1.append(pd.DataFrame([new_row], index=['Reference'], columns=df1.columns))\n",
    "\n",
    "# Print the final DataFrame 'df2' \n",
    "print(df2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tables4'></a>\n",
    "## Table S4 and S5 - Periodic CCSD(T) Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between definition 2 and 1 of Eint: 5 meV\n"
     ]
    }
   ],
   "source": [
    "# We calculate the effect of shifting molecule by 5 A to get Eint in second definition is only a small contribution of 0 meV w.r.t. first Eint definition in Eq. 2 of main text\n",
    "\n",
    "# Calculate the energy difference for the second definition of Eint\n",
    "a = find_energy('Data/DFT/Convergence/CO_Mg-Distance/BOUND/OUTCAR',code_format='vasp')\n",
    "b = find_energy('Data/DFT/Convergence/CO_Mg-Distance/UNBOUND/OUTCAR',code_format='vasp')\n",
    "eint_2 = a - b\n",
    "\n",
    "# Calculate the energy difference for the first definition of Eint\n",
    "c = find_energy('Data/DFT/Convergence/CO_Mg-Distance/SLAB_FS/OUTCAR',code_format='vasp')\n",
    "d = find_energy('Data/DFT/Convergence/CO_Mg-Distance/AD_FS/OUTCAR',code_format='vasp')\n",
    "eint_1 = a - (c + d)\n",
    "\n",
    "# Print the energy difference\n",
    "print('Difference between definition 2 and 1 of Eint: {0:.0f} meV'.format((eint_2-eint_1)*1000) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF 1x1x1             41.30 meV\n",
      "CCSD corr          -158.69 meV\n",
      "CCSD FS             -18.44 meV\n",
      "CCSD BSIE             1.63 meV\n",
      "(T) corr            -47.73 meV\n",
      "Eint2L_CCSD(T)     -181.92 meV\n"
     ]
    }
   ],
   "source": [
    "# Converging the periodic CCSD(T) calculations in Table S4\n",
    "\n",
    "# Method-to-file mapping for different contributions to the periodic CCSD(T) interaction energy.\n",
    "method_to_file = {\n",
    "    'HF 1x1x1': ['OUTCAR.2L.', '.HF.1x1x1'],\n",
    "    'CCSD corr': ['cc4s.2L.', '.CCSD.1x1x1'],\n",
    "    'CCSD FS': ['cc4s.2L.', '.CCSD.1x1x1'],\n",
    "    'CCSD BSIE': ['cc4s.2L.', '.CCSD.1x1x1'],\n",
    "    '(T) corr': ['cc4s.2L.', '.pT.1x1x1']\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store energy contributions\n",
    "ene_pccsd_contributions = {x: 0 for x in method_to_file}\n",
    "\n",
    "# Loop through each contribution and get the energy difference between bound and unbound calculations\n",
    "for i in method_to_file:\n",
    "    ene_dummy = []\n",
    "    for j in ['bound', 'unbound']:\n",
    "        if 'HF' in i:\n",
    "            ene_dummy += [find_energy('Data/Periodic_CC/{0}{1}{2}'.format(method_to_file[i][0], j, method_to_file[i][1]), code_format='cc4s', typ='HF')]\n",
    "        else:\n",
    "            ene_dummy += [find_energy('Data/Periodic_CC/{0}{1}{2}'.format(method_to_file[i][0], j, method_to_file[i][1]), code_format='cc4s', typ=i)]\n",
    "    ene_pccsd_contributions[i] = (ene_dummy[0] - ene_dummy[1]) * 1000\n",
    "\n",
    "# Calculate the total CCSD(T) energy and add it to the contributions\n",
    "ene_pccsd_contributions['Eint2L_CCSD(T)'] = np.sum([ene_pccsd_contributions[x] for x in method_to_file])\n",
    "\n",
    "# Print each contribution and its value in meV\n",
    "for i in ene_pccsd_contributions:\n",
    "    print('{0} {1:10.2f} meV'.format(i.ljust(15), ene_pccsd_contributions[i]))\n",
    "\n",
    "# Update the energy dictionary with Periodic CCSD(T) contributions\n",
    "ene_final['Periodic CCSD(T)']['ECCSD(T)_2L'] = [ene_pccsd_contributions['HF 1x1x1'] + ene_pccsd_contributions['CCSD corr'] + ene_pccsd_contributions['(T) corr'] + ene_pccsd_contributions['CCSD BSIE'] + ene_pccsd_contributions['CCSD FS'], 0]\n",
    "ene_final['Periodic CCSD(T)']['Cost'] = 2 * (2 + 6 + 80)  # Rough estimates of the HF, MP2, CCSD and CCSD(T) steps\n",
    "ene_final['Periodic CCSD(T)']['RAM'] = 3000\n",
    "\n",
    "# Calculate 2L to 4L contribution\n",
    "ene_periodic_mp2_layer_conv = {\n",
    "    '2L': 0.0,\n",
    "    '4L': 0.0\n",
    "}\n",
    "\n",
    "# Loop through different layer numbers\n",
    "for i in ['2L', '4L']:\n",
    "    ene_dummy_hf = []\n",
    "    ene_dummy_mp2 = []\n",
    "    for j in ['bound', 'unbound']:\n",
    "        ene_dummy_hf += [find_energy('Data/Periodic_CC/OUTCAR.{0}.{1}.HF.1x1x1'.format(i, j), code_format='cc4s', typ='HF')]\n",
    "        ene_dummy_mp2 += [find_energy('Data/Periodic_CC/OUTCAR.{0}.{1}.MP2-CBS.50NOs.1x1x1'.format(i, j), code_format='cc4s', typ='MP2 corr')]\n",
    "\n",
    "    ene_periodic_mp2_layer_conv[i] = ((ene_dummy_hf[0] - ene_dummy_hf[1] + ene_dummy_mp2[0] - ene_dummy_mp2[1]) * 1000)\n",
    "\n",
    "# Calculate core contribution\n",
    "method_to_file = {\n",
    "    'Mg_sv': '.Mg_sv.',\n",
    "    'Mg_pv': '.',\n",
    "}\n",
    "\n",
    "ene_periodic_mp2_core_correction = {\n",
    "    'Mg_pv': 0.0,\n",
    "    'Mg_sv': 0.0\n",
    "}\n",
    "\n",
    "# Loop through different frozen cores\n",
    "for i in ['Mg_pv', 'Mg_sv']:\n",
    "    ene_dummy_hf = []\n",
    "    ene_dummy_mp2 = []\n",
    "    for j in ['bound', 'unbound']:\n",
    "        ene_dummy_hf += [find_energy('Data/Periodic_CC/OUTCAR.4L{0}{1}.HF.1x1x1'.format(method_to_file[i], j), code_format='cc4s', typ='HF')]\n",
    "        ene_dummy_mp2 += [find_energy('Data/Periodic_CC/OUTCAR.4L{0}{1}.MP2-CBS.50NOs.1x1x1'.format(method_to_file[i], j), code_format='cc4s', typ='MP2 corr')]\n",
    "\n",
    "    ene_periodic_mp2_core_correction[i] = ((ene_dummy_hf[0] - ene_dummy_hf[1] + ene_dummy_mp2[0] - ene_dummy_mp2[1]) * 1000)\n",
    "\n",
    "# Calculate finite size error correction using HF\n",
    "ene_periodic_hf_ipfse = {\n",
    "    '1x1x1': 0.0,\n",
    "    '2x2x1': 0.0\n",
    "}\n",
    "\n",
    "# Loop through different k-point grids\n",
    "for i in ['1x1x1', '2x2x1']:\n",
    "    ene_dummy_hf = []\n",
    "    for j in ['bound', 'unbound']:\n",
    "        ene_dummy_hf += [find_energy('Data/Periodic_CC/OUTCAR.4L.Mg_sv.{0}.HF.{1}'.format(j, i), code_format='cc4s', typ='HF')]\n",
    "\n",
    "    ene_periodic_hf_ipfse[i] = ((ene_dummy_hf[0] - ene_dummy_hf[1]) * 1000)\n",
    "\n",
    "# Update energy dictionary with additional contributions\n",
    "ene_final['Periodic CCSD(T)']['DeltaMP2_core'] = [0, 0]\n",
    "ene_final['Periodic CCSD(T)']['DeltaMP2_core'][0] = ene_periodic_mp2_layer_conv['4L'] - ene_periodic_mp2_layer_conv['2L']\n",
    "ene_final['Periodic CCSD(T)']['DeltaMP2_2L-4L'][0] = ene_periodic_mp2_core_correction['Mg_sv'] - ene_periodic_mp2_core_correction['Mg_pv']\n",
    "ene_final['Periodic CCSD(T)']['DeltaHF_IPFSE'][0] = ene_periodic_hf_ipfse['2x2x1'] - ene_periodic_hf_ipfse['1x1x1']\n",
    "ene_final['Periodic CCSD(T)']['Delta_geom'] = delta_geom\n",
    "\n",
    "# Calculate basis set convergence contribution at the ccsd level\n",
    "ene_periodic_ccsd_bs_conv = {x: {'Value': 0, 'Diff': 0} for x in [5, 10, 15]}\n",
    "\n",
    "# Loop through different basis set sizes\n",
    "for i in [15, 10, 5]:\n",
    "    ene_dummy = []\n",
    "    for j in ['bound', 'unbound']:\n",
    "        ene_dummy += [find_energy('Data/Periodic_CC/CC_basis_conv_test/cc4s.2Lfrozen.{0}.CCSD.{1}NOs.1x1x1'.format(j, i), code_format='cc4s', typ='CCSD corr') + find_energy('Data/Periodic_CC/CC_basis_conv_test/cc4s.2Lfrozen.{0}.CCSD.{1}NOs.1x1x1'.format(j, i), code_format='cc4s', typ='CCSD BSIE')]\n",
    "    ene_periodic_ccsd_bs_conv[i]['Value'] = (ene_dummy[0] - ene_dummy[1]) * 1000\n",
    "    ene_periodic_ccsd_bs_conv[i]['Diff'] = ene_periodic_ccsd_bs_conv[i]['Value'] - ene_periodic_ccsd_bs_conv[15]['Value']\n",
    "\n",
    "# Update energy dictionary with basis set convergence contributions\n",
    "ene_final['Periodic CCSD(T)']['ECCSD(T)_2L'][1] = ene_periodic_ccsd_bs_conv[10]['Diff']\n",
    "\n",
    "# Calculate and update the final CCSD(T) adsorption energy with its uncertainty\n",
    "ene_final['Periodic CCSD(T)']['Final'][0] = np.sum([ene_final['Periodic CCSD(T)'][x][0] for x in ['ECCSD(T)_2L', 'DeltaMP2_2L-4L', 'DeltaMP2_core', 'DeltaHF_IPFSE', 'Delta_geom']])\n",
    "ene_final['Periodic CCSD(T)']['Final'][1] = np.sqrt(np.sum([ene_final['Periodic CCSD(T)'][x][1]**2 for x in ['ECCSD(T)_2L', 'DeltaMP2_2L-4L', 'DeltaMP2_core', 'DeltaHF_IPFSE', 'Delta_geom']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Value  Diff\n",
      "NOs/occ             \n",
      "5         -205   -46\n",
      "10        -137    22\n",
      "15        -159     0\n"
     ]
    }
   ],
   "source": [
    "# Plotting Table S5 for indicating the basis set convergence at the CCSD level\n",
    "df = pd.DataFrame(ene_periodic_ccsd_bs_conv).T.round().astype(int)\n",
    "df.index.name = 'NOs/occ'\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tables6'></a>\n",
    "## Table S6 - Periodic DMC Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Table S6 for converging DMC calculations for timestep and pseudopotential\n",
    "\n",
    "# Initialize a nested dictionary to store DMC energy results for different structures (slab layer and pseudopotential) and timesteps\n",
    "ene_dmc_list = {x: {y: 0 for y in ['01-1E-1','01-1E-1_2std','02-3E-2','02-3E-2_2std','03-1E-2','03-1E-2_2std']} for x in ['4L','2L', '2L_He']}\n",
    "\n",
    "# Initialize a variable to track the total computational cost in CPUhours\n",
    "total_cost = 0\n",
    "\n",
    "# For 4L structure, 1 is for bound and 2 is for unbound structures respectively.\n",
    "# For 2L structure, 3 is for bound and 4 is for unbound structures respectively.\n",
    "\n",
    "# Getting the interaction energy for 0.1 timestep for 4L and 2L structures. For the 4L structures, the cost for 250 DMC moves is 460 seconds on 448 CPU/MPI processes with 3584 walkers. For the 2L structures, the cost for 2000 moves is 630 seconds on 896 CPU/MPI processes with 3584 walkers.\n",
    "\n",
    "data = []\n",
    "# Loop through structures at 0.1 au timestep to gather DMC data\n",
    "for i in [1,2,3,4]:\n",
    "    a = np.loadtxt('Data/DMC/{0}/01-1E-1/dmc_run_01.hist'.format(i))\n",
    "    b = np.loadtxt('Data/DMC/{0}/01-1E-1/dmc_run_02.hist'.format(i))\n",
    "    dummy_data = np.append(a[3000:,3],b[3000:,3])\n",
    "    if i == 1 or i == 2:\n",
    "        c = np.loadtxt('Data/DMC/{0}/01-1E-1/dmc_run_03.hist'.format(i))\n",
    "        dummy_data = np.append(dummy_data,c[3000:,3])\n",
    "        total_cost += len(dummy_data)*460*448/(250*3600)\n",
    "    else:\n",
    "        total_cost += len(dummy_data)*630*896/(2000*3600)\n",
    "\n",
    "    rand_data = pd.Series(dummy_data*Hartree*1000)\n",
    "    (data_length, reblock_data, covariance) = pyblock.pd_utils.reblock(rand_data)\n",
    "    pyblock.pd_utils.reblock_summary(reblock_data)\n",
    "    data += [pyblock.pd_utils.reblock_summary(reblock_data)]        \n",
    "\n",
    "# Calculate interaction energy (difference between bound and unbound) and uncertainties for different structures and timesteps with pyblock\n",
    "ene_dmc_list['4L']['01-1E-1'] = data[0]['mean'][0] - data[1]['mean'][0]\n",
    "ene_dmc_list['4L']['01-1E-1_2std'] = 2*np.sqrt(data[0]['standard error'][0]**2 + data[1]['standard error'][0]**2)\n",
    "ene_dmc_list['2L']['01-1E-1'] = data[2]['mean'][0] - data[3]['mean'][0]\n",
    "ene_dmc_list['2L']['01-1E-1_2std'] = 2*np.sqrt(data[2]['standard error'][0]**2 + data[3]['standard error'][0]**2)\n",
    "\n",
    "# Getting the interaction energy for 0.03 timestep for 4L. The cost for 250 DMC moves is 460 seconds on 448 CPU/MPI processes with 3584 walkers. \n",
    "\n",
    "data = []\n",
    "# Continue to calculate energy differences and uncertainties for different timesteps and structures\n",
    "for i in [1,2]: #,3,4]:\n",
    "    a = np.loadtxt('Data/DMC/{0}/02-3E-2/dmc_run_01.hist'.format(i))\n",
    "    b = np.loadtxt('Data/DMC/{0}/02-3E-2/dmc_run_02.hist'.format(i))\n",
    "    c = np.loadtxt('Data/DMC/{0}/02-3E-2/dmc_run_03.hist'.format(i))\n",
    "    dummy_data = np.append(a[3000:,3],b[3000:,3])\n",
    "    dummy_data = np.append(dummy_data,c[3000:,3])\n",
    "    if i == 1:\n",
    "        d = np.loadtxt('Data/DMC/{0}/02-3E-2/dmc_run_04.hist'.format(i))\n",
    "        e = np.loadtxt('Data/DMC/{0}/02-3E-2/dmc_run_05.hist'.format(i))\n",
    "        dummy_data = np.append(dummy_data,d[3000:,3])\n",
    "        dummy_data = np.append(dummy_data,e[3000:,3])\n",
    "    rand_data = pd.Series(dummy_data*Hartree*1000)\n",
    "    (data_length, reblock_data, covariance) = pyblock.pd_utils.reblock(rand_data)\n",
    "    pyblock.pd_utils.reblock_summary(reblock_data)\n",
    "    data += [pyblock.pd_utils.reblock_summary(reblock_data)]\n",
    "\n",
    "ene_dmc_list['4L']['02-3E-2'] = data[0]['mean'][0] - data[1]['mean'][0]\n",
    "ene_dmc_list['4L']['02-3E-2_2std'] = 2*np.sqrt(data[0]['standard error'][0]**2 + data[1]['standard error'][0]**2)\n",
    "\n",
    "# Getting the 2L_He at 0.1, 0.03 and 0.01 timestep. The cost for 2000 moves is 980 seconds on 1792 CPU/MPI processes with 7168 walkers.\n",
    "for j in ['01-1E-1','02-3E-2','03-1E-2']:\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i in [3,4]: #,3,4]:\n",
    "        a = np.loadtxt('Data/DMC/{0}_He/{1}/dmc.hist'.format(i,j))\n",
    "        dummy_data = a[3000:,3]\n",
    "\n",
    "        if j == '02-3E-2':\n",
    "            total_cost += len(dummy_data)*980*1792/(2000*3600)\n",
    "\n",
    "\n",
    "        rand_data = pd.Series(dummy_data*Hartree*1000)\n",
    "        (data_length, reblock_data, covariance) = pyblock.pd_utils.reblock(rand_data)\n",
    "        pyblock.pd_utils.reblock_summary(reblock_data)\n",
    "        data += [pyblock.pd_utils.reblock_summary(reblock_data)]\n",
    "\n",
    "    # ene_dmc_list['2L_He'][j] = pyblock.error.subtraction(data[0],data[1],0,1)['mean'][0]\n",
    "    # ene_dmc_list['2L_He'][j + '_2std'] = 2*pyblock.error.subtraction(data[0],data[1],0,1)['standard error'][0]\n",
    "    ene_dmc_list['2L_He'][j] = data[0]['mean'][0] - data[1]['mean'][0]\n",
    "    ene_dmc_list['2L_He'][j + '_2std'] = 2*np.sqrt(data[0]['standard error'][0]**2 + data[1]['standard error'][0]**2)\n",
    "\n",
    "# MPC for 4L structure at 0.1 timestep. The cost for 250 moves is 6400 seconds on 448 CPU/MPI processes with 3584 walkers.\n",
    "data = []\n",
    "\n",
    "for i in [1,2]:\n",
    "    if i == 2:\n",
    "        a = np.loadtxt('Data/DMC/{0}_MPC/01-1E-1/dmc.hist'.format(i))\n",
    "        dummy_data = a[300:,4] - a[300:,3]\n",
    "    elif i == 1:\n",
    "        a1 = np.loadtxt('Data/DMC/{0}_MPC/01-1E-1/dmc_run_01.hist'.format(i))\n",
    "        a2 = np.loadtxt('Data/DMC/{0}_MPC/01-1E-1/dmc_run_02.hist'.format(i))\n",
    "        a3 = np.loadtxt('Data/DMC/{0}_MPC/01-1E-1/dmc_run_03.hist'.format(i))\n",
    "        dummy_data = np.append(a1[300:,4] - a1[300:,3],a2[300:,4] - a2[300:,3])\n",
    "        dummy_data = np.append(dummy_data,a3[300:,4] - a3[300:,3])\n",
    "\n",
    "    total_cost += len(dummy_data)*6400*448/(250*3600)\n",
    "    rand_data = pd.Series(dummy_data*Hartree*1000)\n",
    "    (data_length, reblock_data, covariance) = pyblock.pd_utils.reblock(rand_data)\n",
    "    pyblock.pd_utils.reblock_summary(reblock_data)\n",
    "    data += [pyblock.pd_utils.reblock_summary(reblock_data)]\n",
    "\n",
    "ene_2l = [ene_dmc_list['2L_He']['02-3E-2'], ene_dmc_list['2L_He']['02-3E-2_2std']]\n",
    "delta_fse = [data[0]['mean'][0] - data[1]['mean'][0],2*np.sqrt(data[0]['standard error'][0]**2 + data[1]['standard error'][0]**2)]\n",
    "delta_2l_4l = [ene_dmc_list['4L']['01-1E-1'] - ene_dmc_list['2L']['01-1E-1'], np.sqrt(ene_dmc_list['4L']['01-1E-1_2std']**2 + ene_dmc_list['2L']['01-1E-1_2std']**2)]\n",
    "\n",
    "# Calculating IPFSE by looking at how the LDA energy changes from 1x1x1 and 3x3x1 k-point grids\n",
    "ene_bound = find_energy('Data/DMC/IPFSE/1x1x1/1/outpw',code_format='quantum_espresso')\n",
    "ene_unbound = find_energy('Data/DMC/IPFSE/1x1x1/2/outpw',code_format='quantum_espresso')\n",
    "ene_1x1x1 = (ene_bound - ene_unbound)*1000*Hartree/2\n",
    "\n",
    "ene_bound = find_energy('Data/DMC/IPFSE/3x3x1/1/outpw',code_format='quantum_espresso')\n",
    "ene_unbound = find_energy('Data/DMC/IPFSE/3x3x1/2/outpw',code_format='quantum_espresso')\n",
    "ene_3x3x1 = (ene_bound - ene_unbound)*1000*Hartree/2\n",
    "\n",
    "# Calculate energy difference to get IPFSE\n",
    "delta_ipfse = [ene_3x3x1 - ene_1x1x1,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01-1E-1</th>\n",
       "      <th>01-1E-1_2std</th>\n",
       "      <th>02-3E-2</th>\n",
       "      <th>02-3E-2_2std</th>\n",
       "      <th>03-1E-2</th>\n",
       "      <th>03-1E-2_2std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4L</th>\n",
       "      <td>-142</td>\n",
       "      <td>18</td>\n",
       "      <td>-144</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2L_He</th>\n",
       "      <td>-140</td>\n",
       "      <td>22</td>\n",
       "      <td>-159</td>\n",
       "      <td>14</td>\n",
       "      <td>-161</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       01-1E-1  01-1E-1_2std  02-3E-2  02-3E-2_2std  03-1E-2  03-1E-2_2std\n",
       "4L        -142            18     -144            19        0             0\n",
       "2L_He     -140            22     -159            14     -161            25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign various calculated energy contributions to the 'Periodic DMC' key in the 'ene_final' dictionary\n",
    "\n",
    "# Store the interaction energy for 2L structure at 0.1 timestep\n",
    "ene_final['Periodic DMC']['EDMC_2L'] = ene_2l\n",
    "\n",
    "# Store the energy contribution between 2L and 4L structures\n",
    "ene_final['Periodic DMC']['DeltaDMC_2L-4L'] = delta_2l_4l\n",
    "\n",
    "# Store the energy contribution due to finite-size effects (FSE) using MPC\n",
    "ene_final['Periodic DMC']['DeltaDMC_FSE'] = delta_fse\n",
    "\n",
    "# Store the energy contribution due to independent particle FSE (IPFSE) calculated with LDA\n",
    "ene_final['Periodic DMC']['DeltaLDA_IPFSE'] = delta_ipfse\n",
    "\n",
    "# Store the energy contribution due to geometric relaxation\n",
    "ene_final['Periodic DMC']['Delta_geom'] = delta_geom\n",
    "\n",
    "# Store the calculated total computational cost\n",
    "ene_final['Periodic DMC']['Cost'] = total_cost\n",
    "\n",
    "# RAM usage for DMC is very low\n",
    "ene_final['Periodic DMC']['RAM'] = 0\n",
    "\n",
    "# Calculate and store the final total energy and its associated uncertainty\n",
    "ene_final['Periodic DMC']['Final'][0] = np.sum([ene_final['Periodic DMC'][x][0] for x in ['EDMC_2L', 'DeltaDMC_2L-4L', 'DeltaDMC_FSE', 'DeltaLDA_IPFSE', 'Delta_geom']])\n",
    "ene_final['Periodic DMC']['Final'][1] = np.sqrt(np.sum([ene_final['Periodic DMC'][x][1]**2 for x in ['EDMC_2L', 'DeltaDMC_2L-4L', 'DeltaDMC_FSE', 'DeltaLDA_IPFSE', 'Delta_geom']]))\n",
    "\n",
    "# Create a DataFrame 'df' using the 'ene_dmc_list' dictionary\n",
    "df = pd.DataFrame(ene_dmc_list)\n",
    "\n",
    "# Transpose and round the DataFrame 'df1', and convert its values to integers\n",
    "df1 = df[['4L', '2L_He']].T\n",
    "df1 = df1.round().astype(int)\n",
    "\n",
    "\n",
    "# Display the rounded and transposed DataFrame 'df1'\n",
    "df1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tables7'></a>\n",
    "## Table S7 - DFT Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Supercell Size</th>\n",
       "      <th>Number of Layers</th>\n",
       "      <th>K-point Mesh</th>\n",
       "      <th>Energy cutoff</th>\n",
       "      <th>PREC(ision)</th>\n",
       "      <th>Vacuum</th>\n",
       "      <th>Eads</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4x4</td>\n",
       "      <td>4</td>\n",
       "      <td>2x2x1</td>\n",
       "      <td>600</td>\n",
       "      <td>Normal</td>\n",
       "      <td>15</td>\n",
       "      <td>-206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6x6</td>\n",
       "      <td>4</td>\n",
       "      <td>2x2x1</td>\n",
       "      <td>600</td>\n",
       "      <td>Normal</td>\n",
       "      <td>15</td>\n",
       "      <td>-203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4x4</td>\n",
       "      <td>6</td>\n",
       "      <td>2x2x1</td>\n",
       "      <td>600</td>\n",
       "      <td>Normal</td>\n",
       "      <td>15</td>\n",
       "      <td>-207</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4x4</td>\n",
       "      <td>4</td>\n",
       "      <td>3x3x1</td>\n",
       "      <td>700</td>\n",
       "      <td>Accurate</td>\n",
       "      <td>15</td>\n",
       "      <td>-206</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4x4</td>\n",
       "      <td>4</td>\n",
       "      <td>2x2x1</td>\n",
       "      <td>600</td>\n",
       "      <td>Normal</td>\n",
       "      <td>20</td>\n",
       "      <td>-207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Supercell Size Number of Layers K-point Mesh Energy cutoff PREC(ision)  \\\n",
       "1            4x4                4        2x2x1           600      Normal   \n",
       "2            6x6                4        2x2x1           600      Normal   \n",
       "3            4x4                6        2x2x1           600      Normal   \n",
       "4            4x4                4        3x3x1           700    Accurate   \n",
       "5            4x4                4        2x2x1           600      Normal   \n",
       "\n",
       "  Vacuum  Eads  Diff  \n",
       "1     15  -206     0  \n",
       "2     15  -203     3  \n",
       "3     15  -207    -1  \n",
       "4     15  -206     1  \n",
       "5     20  -207     0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Effects of layer convergence and other factors on the adsorption energy for Table S7\n",
    "\n",
    "# Create a dictionary 'eads_dft_conv' to store different parameters and their corresponding adsorption energy calculations\n",
    "eads_dft_conv = {\n",
    "    1: {\n",
    "        'Supercell Size': '4x4' ,\n",
    "        'Number of Layers': '4' ,\n",
    "        'K-point Mesh': '2x2x1',\n",
    "        'Energy cutoff': '600',\n",
    "        'PREC(ision)': 'Normal',\n",
    "        'Vacuum': '15',\n",
    "        'Eads': 0,\n",
    "        'Diff': 0\n",
    "    },\n",
    "    2: {\n",
    "        'Supercell Size': '6x6' ,\n",
    "        'Number of Layers': '4' ,\n",
    "        'K-point Mesh': '2x2x1',\n",
    "        'Energy cutoff': '600',\n",
    "        'PREC(ision)': 'Normal',\n",
    "        'Vacuum': '15',\n",
    "        'Eads': 0,\n",
    "        'Diff': 0\n",
    "    },\n",
    "    3: {\n",
    "        'Supercell Size': '4x4' ,\n",
    "        'Number of Layers': '6' ,\n",
    "        'K-point Mesh': '2x2x1',\n",
    "        'Energy cutoff': '600',\n",
    "        'PREC(ision)': 'Normal',\n",
    "        'Vacuum': '15',\n",
    "        'Eads': 0,\n",
    "        'Diff': 0\n",
    "    },\n",
    "    4: {\n",
    "        'Supercell Size': '4x4' ,\n",
    "        'Number of Layers': '4' ,\n",
    "        'K-point Mesh': '3x3x1',\n",
    "        'Energy cutoff': '700',\n",
    "        'PREC(ision)': 'Accurate',\n",
    "        'Vacuum': '15',\n",
    "        'Eads': 0,\n",
    "        'Diff': 0\n",
    "    },\n",
    "    5: {\n",
    "        'Supercell Size': '4x4' ,\n",
    "        'Number of Layers': '4' ,\n",
    "        'K-point Mesh': '2x2x1',\n",
    "        'Energy cutoff': '600',\n",
    "        'PREC(ision)': 'Normal',\n",
    "        'Vacuum': '20',\n",
    "        'Eads': 0,\n",
    "        'Diff': 0\n",
    "    }\n",
    "}\n",
    "# Iterate over the different electronic structure settings and calculate Eads\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    # Perform energy calculations for AD_SLAB, AD, and SLAB configurations\n",
    "    ad_slab = find_energy('Data/DFT/Convergence/{0}/AD_SLAB/OUTCAR'.format(i), code_format='vasp')\n",
    "    ad = find_energy('Data/DFT/Convergence/{0}/AD/OUTCAR'.format(i), code_format='vasp')\n",
    "    slab = find_energy('Data/DFT/Convergence/{0}/SLAB/OUTCAR'.format(i), code_format='vasp')\n",
    "\n",
    "    # Calculate the adsorption energy\n",
    "    eads = (ad_slab - ad - slab) * 1000\n",
    "\n",
    "    # If it's the first iteration, store the reference adsorption energy\n",
    "    if i == 1:\n",
    "        eads0 = eads\n",
    "    \n",
    "    # Store calculated adsorption energy and the difference from the reference\n",
    "    eads_dft_conv[i]['Eads'] = eads\n",
    "    eads_dft_conv[i]['Diff'] = (eads - eads0)\n",
    "\n",
    "# Create a DataFrame 'df' from the 'eads_dft_conv' dictionary\n",
    "df = pd.DataFrame(eads_dft_conv).T\n",
    "\n",
    "# Round the 'Eads' and 'Diff' columns to integers\n",
    "df['Eads'] = df['Eads'].apply(lambda x: round(x))\n",
    "df['Diff'] = df['Diff'].apply(lambda x: round(x))\n",
    "\n",
    "# Display the final DataFrame 'df'\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tables9-s11'></a>\n",
    "## Table S9 to S11 and Figure 2 - SKZCAM Cluster CCSD(T) Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining data for Table S9 of adsorption energies at MP2 and CCSD(T) levels with increasing cluster size.\n",
    "\n",
    "# Define of levels of theories 'lot_list' and initialize dictionaries to store adsorption energy results\n",
    "\n",
    "lot_list = ['MP2_DZ', 'MP2_TZ', 'MP2_QZ', 'MP2_TZQZ', 'MP2_DZTZ', 'MP2_DZTZ_lc', 'MP2_DZTZ_lc_NOCP', 'LCCSDT_DZTZ', 'LMP2_DZTZ', 'CCCSDT_TZQZ', 'CMP2_TZQZ']\n",
    "ene_list = {y: [] for y in lot_list}\n",
    "ene_extrap_list = {y: [] for y in lot_list}\n",
    "tot_atom_list = [6, 22, 34, 42, 58, 82, 84, 100, 108]  # List of total atom count with cluster size\n",
    "\n",
    "\n",
    "total_cputime = 0 # Initialize total CPU time variable\n",
    "\n",
    "# Calculating interaction energy at the MP2 DZ level and also extrapolate to the bulk size limit given a set of these clusters\n",
    "for j in range(1,9):\n",
    "    # Calculate adsorption energy from difference of AD_SLAB, SLAB_CP, and AD_CP, where CP means counterpoise corrected (i.e. ghost basis sets have been placed)\n",
    "    ene_list['MP2_DZ'] += [get_eads('Data/MP2_Convergence/{0}/DZ'.format(j), code_format='mrcc',typ='lmp2_tot')*Hartree*1000]\n",
    "    if j < 3:\n",
    "        ene_extrap_list['MP2_DZ'] += [0]\n",
    "    # Extrapolate if we have more than 3 clusters\n",
    "    else:\n",
    "        gamma_best = find_co_gamma(ene_list['MP2_DZ'])\n",
    "        slope, emp2_infty, r, p, se = linregress([1/(x**(gamma_best)) for x in tot_atom_list[:len(ene_list['MP2_DZ'])]],\\\n",
    "            [float(x) for x in ene_list['MP2_DZ']])\n",
    "        ene_extrap_list['MP2_DZ'] += [emp2_infty]\n",
    "    # Add to total CPU time\n",
    "    for l in ['AD_SLAB','SLAB_CP','AD_CP']:\n",
    "        total_cputime += get_mrcc_walltime('Data/MP2_Convergence/{0}/DZ/{1}/mrcc.out'.format(j,l))*36/3600\n",
    "\n",
    "# Repeat for MP2 TZ\n",
    "for j in range(1,6):\n",
    "    ene_hf = []\n",
    "    ene_mp2 = []\n",
    "    for k in ['TZ','QZ']:\n",
    "        ene_list['MP2_'+k] += [get_eads('Data/MP2_Convergence/{0}/{1}'.format(j,k), code_format='mrcc',typ='lmp2_tot')*Hartree*1000]\n",
    "        ene_hf += [get_eads('Data/MP2_Convergence/{0}/{1}'.format(j,k), code_format='mrcc',typ='hf')*Hartree*1000]\n",
    "        ene_mp2 += [get_eads('Data/MP2_Convergence/{0}/{1}'.format(j,k), code_format='mrcc',typ='lmp2_corr')*Hartree*1000]\n",
    "        for l in ['AD_SLAB','SLAB_CP','AD_CP']:\n",
    "            total_cputime += get_mrcc_walltime('Data/MP2_Convergence/{0}/{1}/{2}/mrcc.out'.format(j,k,l))*36/3600\n",
    "    dummy = extrapolate.get_cbs(ene_hf[0],ene_mp2[0],ene_hf[1],ene_mp2[1],X=3,Y=4,family='mixcc',output=False)\n",
    "    ene_list['MP2_TZQZ'] += [dummy[-1]]\n",
    "\n",
    "    if j < 3:\n",
    "        ene_extrap_list['MP2_TZQZ'] += [0]\n",
    "    else:\n",
    "        gamma_best = find_co_gamma(ene_list['MP2_TZQZ'])\n",
    "        slope, emp2_infty, r, p, se = linregress([1/(x**(gamma_best)) for x in tot_atom_list[:len(ene_list['MP2_TZQZ'])]],\\\n",
    "            [float(x) for x in ene_list['MP2_TZQZ']])\n",
    "        ene_extrap_list['MP2_TZQZ'] += [emp2_infty]\n",
    "\n",
    "# Perform basis set extrapolation for MP2 DZTZ with a large frozen core (for Sec. S8)\n",
    "for j in range(1,6):\n",
    "    ene_hf = []\n",
    "    ene_mp2 = []\n",
    "    for k in ['DZ','TZ']:\n",
    "        ene_hf += [get_eads('Data/MP2_Convergence/{0}/{1}_lc'.format(j,k), code_format='mrcc',typ='hf')*Hartree*1000]\n",
    "        ene_mp2 += [get_eads('Data/MP2_Convergence/{0}/{1}_lc'.format(j,k), code_format='mrcc',typ='lmp2_corr')*Hartree*1000]\n",
    "    dummy = extrapolate.get_cbs(ene_hf[0],ene_mp2[0],ene_hf[1],ene_mp2[1],X=2,Y=3,family='mixcc',output=False)\n",
    "    ene_list['MP2_DZTZ_lc'] += [dummy[-1]]\n",
    "\n",
    "    if j < 3:\n",
    "        ene_extrap_list['MP2_DZTZ_lc'] += [0]\n",
    "    else:\n",
    "        gamma_best = find_co_gamma(ene_list['MP2_DZTZ_lc'])\n",
    "        slope, emp2_infty, r, p, se = linregress([1/(x**(gamma_best)) for x in tot_atom_list[:len(ene_list['MP2_DZTZ_lc'])]],\\\n",
    "            [float(x) for x in ene_list['MP2_DZTZ_lc']])\n",
    "        ene_extrap_list['MP2_DZTZ_lc'] += [emp2_infty]\n",
    "\n",
    "# Perform basis set extrapolation for MP2 DZTZ with no counterpoise correction (for Sec. S8)\n",
    "for j in range(1,6):\n",
    "    ene_hf = []\n",
    "    ene_mp2 = []\n",
    "    for k in ['DZ','TZ']:\n",
    "        ene_hf += [get_eads('Data/MP2_Convergence/{0}/{1}_lc'.format(j,k), code_format='mrcc',typ='hf',structs=['AD_SLAB','SLAB_NOCP','AD_NOCP'])*Hartree*1000]\n",
    "        ene_mp2 += [get_eads('Data/MP2_Convergence/{0}/{1}_lc'.format(j,k), code_format='mrcc',typ='lmp2_corr',structs=['AD_SLAB','SLAB_NOCP','AD_NOCP'])*Hartree*1000]\n",
    "    dummy = extrapolate.get_cbs(ene_hf[0],ene_mp2[0],ene_hf[1],ene_mp2[1],X=2,Y=3,family='mixcc',output=False)\n",
    "    ene_list['MP2_DZTZ_lc_NOCP'] += [dummy[-1]]\n",
    "    if j < 3:\n",
    "        ene_extrap_list['MP2_DZTZ_lc_NOCP'] += [0]\n",
    "    else:\n",
    "        gamma_best = find_co_gamma(ene_list['MP2_DZTZ_lc_NOCP'])\n",
    "        slope, emp2_infty, r, p, se = linregress([1/(x**(gamma_best)) for x in tot_atom_list[:len(ene_list['MP2_DZTZ_lc_NOCP'])]],[float(x) for x in ene_list['MP2_DZTZ_lc_NOCP']])\n",
    "        ene_extrap_list['MP2_DZTZ_lc_NOCP'] += [emp2_infty]\n",
    "\n",
    "# Perform basis set extrapolation for MP2 DZTZ with small frozen core (default converged settings)\n",
    "for j in range(1,6):\n",
    "    ene_hf = []\n",
    "    ene_mp2 = []\n",
    "    for k in ['DZ','TZ']:\n",
    "        ene_hf += [get_eads('Data/MP2_Convergence/{0}/{1}'.format(j,k), code_format='mrcc',typ='hf')*Hartree*1000]\n",
    "        ene_mp2 += [get_eads('Data/MP2_Convergence/{0}/{1}'.format(j,k), code_format='mrcc',typ='lmp2_corr')*Hartree*1000]\n",
    "    dummy = extrapolate.get_cbs(ene_hf[0],ene_mp2[0],ene_hf[1],ene_mp2[1],X=2,Y=3,family='mixcc',output=False)\n",
    "    ene_list['MP2_DZTZ'] += [dummy[-1]]\n",
    "\n",
    "    if j < 3:\n",
    "        ene_extrap_list['MP2_DZTZ'] += [0]\n",
    "    else:\n",
    "        gamma_best = find_co_gamma(ene_list['MP2_DZTZ'])\n",
    "        slope, emp2_infty, r, p, se = linregress([1/(x**(gamma_best)) for x in tot_atom_list[:len(ene_list['MP2_DZTZ'])]],\\\n",
    "            [float(x) for x in ene_list['MP2_DZTZ']])\n",
    "        ene_extrap_list['MP2_DZTZ'] += [emp2_infty]\n",
    "\n",
    "# Perform basis set extrapolation for LNO-CCSD(T) DZTZ\n",
    "for j in range(1,4):\n",
    "    ene_hf = []\n",
    "    ene_mp2 = []\n",
    "    for k in ['DZ','TZ']:\n",
    "        ene_hf += [get_eads('Data/CC_Convergence/{0}_Local/{1}'.format(j,k), code_format='mrcc',typ='hf')*Hartree*1000]\n",
    "        ene_mp2 += [get_eads('Data/CC_Convergence/{0}_Local/{1}'.format(j,k), code_format='mrcc',typ='lccsdt')*Hartree*1000]\n",
    "        for l in ['AD_SLAB','SLAB_CP','AD_CP']:\n",
    "            total_cputime += get_mrcc_walltime('Data/CC_Convergence/{0}_Local/{1}/{2}/mrcc.out'.format(j,k,l))*36/3600\n",
    "    dummy = extrapolate.get_cbs(ene_hf[0],ene_mp2[0],ene_hf[1],ene_mp2[1],X=2,Y=3,family='mixcc',output=False)\n",
    "    ene_list['LCCSDT_DZTZ'] += [dummy[-1]]\n",
    "    # Also add LMP2 DZTZ numbers\n",
    "    ene_hf = []\n",
    "    ene_mp2 = []\n",
    "    for k in ['DZ','TZ']:\n",
    "        ene_hf += [get_eads('Data/CC_Convergence/{0}_Local/{1}'.format(j,k), code_format='mrcc',typ='hf')*Hartree*1000]\n",
    "        ene_mp2 += [get_eads('Data/CC_Convergence/{0}_Local/{1}'.format(j,k), code_format='mrcc',typ='lmp2')*Hartree*1000]\n",
    "    dummy = extrapolate.get_cbs(ene_hf[0],ene_mp2[0],ene_hf[1],ene_mp2[1],X=2,Y=3,family='mixcc',output=False)\n",
    "    ene_list['LMP2_DZTZ'] += [dummy[-1]]\n",
    "\n",
    "# Perform basis set extrapolation for canonical CCSD(T) TZQZ\n",
    "for j in range(1,2):\n",
    "    ene_hf = []\n",
    "    ene_mp2 = []\n",
    "    for k in ['TZ','QZ']:\n",
    "        ene_hf += [get_eads('Data/CC_Convergence/{0}_Canonical/{1}'.format(j,k), code_format='mrcc',typ='hf')*Hartree*1000]\n",
    "        ene_mp2 += [get_eads('Data/CC_Convergence/{0}_Canonical/{1}'.format(j,k), code_format='mrcc',typ='ccsdt')*Hartree*1000]\n",
    "        for l in ['AD_SLAB','SLAB_CP','AD_CP']:\n",
    "            total_cputime += get_mrcc_walltime('Data/CC_Convergence/{0}_Canonical/{1}/{2}/mrcc.out'.format(j,k,l))*36/3600\n",
    "    dummy = extrapolate.get_cbs(ene_hf[0],ene_mp2[0],ene_hf[1],ene_mp2[1],X=3,Y=4,family='mixcc',output=False)\n",
    "    ene_list['CCCSDT_TZQZ'] += [dummy[-1]]\n",
    "    ene_hf = []\n",
    "    ene_mp2 = []\n",
    "    for k in ['TZ','QZ']:\n",
    "        ene_hf += [get_eads('Data/CC_Convergence/{0}_Canonical/{1}'.format(j,k), code_format='mrcc',typ='hf')*Hartree*1000]\n",
    "        ene_mp2 += [get_eads('Data/CC_Convergence/{0}_Canonical/{1}'.format(j,k), code_format='mrcc',typ='mp2')*Hartree*1000]\n",
    "    dummy = extrapolate.get_cbs(ene_hf[0],ene_mp2[0],ene_hf[1],ene_mp2[1],X=3,Y=4,family='mixcc',output=False)\n",
    "    ene_list['CMP2_TZQZ'] += [dummy[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># of atoms</th>\n",
       "      <th>MP2 DZ</th>\n",
       "      <th>MP2 TZ</th>\n",
       "      <th>MP2 QZ</th>\n",
       "      <th>MP2 CBS(TZ/QZ)</th>\n",
       "      <th>LMP2 CBS(DZ/TZ)</th>\n",
       "      <th>LNO-CCSD(T) CBS(DZ/TZ)</th>\n",
       "      <th>CCSD(T) CBS(TZ/QZ)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>-45</td>\n",
       "      <td>-119</td>\n",
       "      <td>-140</td>\n",
       "      <td>-153</td>\n",
       "      <td>-154</td>\n",
       "      <td>-159</td>\n",
       "      <td>-160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>-99</td>\n",
       "      <td>-155</td>\n",
       "      <td>-173</td>\n",
       "      <td>-184</td>\n",
       "      <td>-184</td>\n",
       "      <td>-191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>-110</td>\n",
       "      <td>-164</td>\n",
       "      <td>-178</td>\n",
       "      <td>-188</td>\n",
       "      <td>-187</td>\n",
       "      <td>-195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>-116</td>\n",
       "      <td>-168</td>\n",
       "      <td>-182</td>\n",
       "      <td>-192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58</td>\n",
       "      <td>-122</td>\n",
       "      <td>-171</td>\n",
       "      <td>-184</td>\n",
       "      <td>-193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>82</td>\n",
       "      <td>-127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84</td>\n",
       "      <td>-128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>-131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # of atoms  MP2 DZ  MP2 TZ  MP2 QZ  MP2 CBS(TZ/QZ)  LMP2 CBS(DZ/TZ)  \\\n",
       "1           6     -45    -119    -140            -153             -154   \n",
       "2          22     -99    -155    -173            -184             -184   \n",
       "3          34    -110    -164    -178            -188             -187   \n",
       "4          42    -116    -168    -182            -192                0   \n",
       "5          58    -122    -171    -184            -193                0   \n",
       "6          82    -127       0       0               0                0   \n",
       "7          84    -128       0       0               0                0   \n",
       "8         100    -131       0       0               0                0   \n",
       "\n",
       "   LNO-CCSD(T) CBS(DZ/TZ)  CCSD(T) CBS(TZ/QZ)  \n",
       "1                    -159                -160  \n",
       "2                    -191                   0  \n",
       "3                    -195                   0  \n",
       "4                       0                   0  \n",
       "5                       0                   0  \n",
       "6                       0                   0  \n",
       "7                       0                   0  \n",
       "8                       0                   0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting out Table S9\n",
    "# Initialize an empty dictionary 'trunc_ene_list' to store extrapolate interaction energies for truncating below 8 clusters\n",
    "trunc_ene_list = {}\n",
    "\n",
    "# Loop through a list of electronic structure method names ('MP2_DZ', 'MP2_TZ', etc.)\n",
    "for i in ['MP2_DZ', 'MP2_TZ', 'MP2_QZ', 'MP2_TZQZ', 'LMP2_DZTZ', 'LCCSDT_DZTZ', 'CCCSDT_TZQZ']:\n",
    "    # Check if the length of the energy list 'ene_list[i]' is less than 8\n",
    "    if len(ene_list[i]) < 8:\n",
    "        # Calculate the difference in length needed to make it 8\n",
    "        dff_len = 8 - len(ene_list[i])\n",
    "        # Create a truncated energy list by adding zeros to meet the length of 8\n",
    "        trunc_ene_list[i] = ene_list[i] + [0] * dff_len\n",
    "    else:\n",
    "        # If the energy list already has at least 8 values, keep it as is\n",
    "        trunc_ene_list[i] = ene_list[i]\n",
    "\n",
    "# Create a DataFrame 'df' using the truncated energy lists\n",
    "df = pd.DataFrame(trunc_ene_list)\n",
    "\n",
    "# Rename the columns of the DataFrame\n",
    "df.columns = ['MP2 DZ', 'MP2 TZ', 'MP2 QZ', 'MP2 CBS(TZ/QZ)', 'LMP2 CBS(DZ/TZ)', 'LNO-CCSD(T) CBS(DZ/TZ)', 'CCSD(T) CBS(TZ/QZ)']\n",
    "\n",
    "# Create a new column '# of atoms' and populate it with the first 8 elements of 'tot_atom_list'\n",
    "df['# of atoms'] = tot_atom_list[:8]\n",
    "\n",
    "# Rearrange the columns in the DataFrame and round the values to integers\n",
    "df = df[['# of atoms', 'MP2 DZ', 'MP2 TZ', 'MP2 QZ', 'MP2 CBS(TZ/QZ)', 'LMP2 CBS(DZ/TZ)', 'LNO-CCSD(T) CBS(DZ/TZ)', 'CCSD(T) CBS(TZ/QZ)']]\n",
    "df = df.round().astype(int)\n",
    "\n",
    "# Increment the index of the DataFrame by 1\n",
    "df.index += 1\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MP2 DZ</th>\n",
       "      <th>MP2_DZ_Error</th>\n",
       "      <th>MP2 CBS(TZ/QZ)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-156</td>\n",
       "      <td>4</td>\n",
       "      <td>-194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-174</td>\n",
       "      <td>15</td>\n",
       "      <td>-202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-164</td>\n",
       "      <td>5</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-158</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MP2 DZ  MP2_DZ_Error  MP2 CBS(TZ/QZ)\n",
       "3    -156             4            -194\n",
       "4    -174            15            -202\n",
       "5    -164             5            -200\n",
       "6    -157             3               0\n",
       "7    -158             1               0\n",
       "8    -159             0               0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting out Table S10\n",
    "\n",
    "# Initialize an empty dictionary 'trunc_ene_extrap_list' to store truncated and extrapolated interaction energies at the various MP2 basis sets\n",
    "trunc_ene_extrap_list = {}\n",
    "\n",
    "# Loop through a list of basis sets ('MP2_DZ', 'MP2_DZ_Error', 'MP2_TZQZ')\n",
    "for i in ['MP2_DZ', 'MP2_DZ_Error', 'MP2_TZQZ']:\n",
    "    \n",
    "    # We can calculate the error from truncating the number of clusters below 8 only for the 'MP2_DZ' basis set\n",
    "    if i == 'MP2_DZ_Error':\n",
    "        # Calculate the absolute difference between each value and the last value (for 8 clusters)\n",
    "        # Store these differences starting from the third element onwards (index 2)\n",
    "        trunc_ene_extrap_list[i] = [abs(x - ene_extrap_list['MP2_DZ'][-1]) for x in ene_extrap_list['MP2_DZ']][2:]\n",
    "        continue\n",
    "    \n",
    "    # For MP2_TZQZ which only has 3 clusters, we have to pad the list to allow for plotting a table\n",
    "    if len(ene_extrap_list[i]) < 8:\n",
    "        # Calculate the difference in length needed to make it 8\n",
    "        dff_len = 8 - len(ene_extrap_list[i])\n",
    "        # Create a truncated and padded extrapolated energy list by adding zeros to meet the length of 8, \n",
    "        # then remove the first two elements (index 0 and 1)\n",
    "        trunc_ene_extrap_list[i] = (ene_extrap_list[i] + [0] * dff_len)[2:]\n",
    "    else:\n",
    "        # If the extrapolated energy list already has at least 8 values, keep the last six values (index 2 to 7)\n",
    "        trunc_ene_extrap_list[i] = ene_extrap_list[i][2:]\n",
    "\n",
    "# Create a DataFrame 'df'\n",
    "df = pd.DataFrame(trunc_ene_extrap_list)\n",
    "\n",
    "# Rename the columns of the DataFrame\n",
    "df.columns = ['MP2 DZ', 'MP2_DZ_Error', 'MP2 CBS(TZ/QZ)']\n",
    "\n",
    "# Increment the index of the DataFrame by 3\n",
    "df.index += 3\n",
    "\n",
    "# Create a new DataFrame 'df1' with rounded integer values\n",
    "df1 = df.round().astype(int)\n",
    "\n",
    "# Assign the values from the DataFrame 'df' to the 'ene_final' dictionary\n",
    "ene_final['Cluster CCSD(T)']['EMP2_Bulklimit'] = [df['MP2 CBS(TZ/QZ)'][5], df['MP2_DZ_Error'][5]]\n",
    "\n",
    "# Print the DataFrame 'df1'\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LMP2_DZTZ</th>\n",
       "      <th>LCCSDT_DZTZ</th>\n",
       "      <th>deltacc_local</th>\n",
       "      <th>CMP2_TZQZ</th>\n",
       "      <th>CCCSDT_TZQZ</th>\n",
       "      <th>deltacc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-154</td>\n",
       "      <td>-159</td>\n",
       "      <td>-5</td>\n",
       "      <td>-153</td>\n",
       "      <td>-160</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-184</td>\n",
       "      <td>-191</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-187</td>\n",
       "      <td>-195</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LMP2_DZTZ  LCCSDT_DZTZ  deltacc_local  CMP2_TZQZ  CCCSDT_TZQZ  deltacc\n",
       "1       -154         -159             -5       -153         -160       -7\n",
       "2       -184         -191             -7          0            0        0\n",
       "3       -187         -195             -8          0            0        0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting Table S11 on the difference in delta correction between local approximation against canonical MP2 + CCSD(T).\n",
    "# Initialize an empty dictionary 'trunc_ene_cc_list' to store truncated cluster correlation energy lists\n",
    "trunc_ene_cc_list = {}\n",
    "\n",
    "# Loop through a list of cluster correlation energy method names ('LMP2_DZTZ', 'LCCSDT_DZTZ', 'CMP2_TZQZ', 'CCCSDT_TZQZ')\n",
    "for i in ['LMP2_DZTZ', 'LCCSDT_DZTZ', 'CMP2_TZQZ', 'CCCSDT_TZQZ']:\n",
    "    \n",
    "    # Check if the length of the current cluster correlation energy list 'ene_list[i]' is less than 3\n",
    "    if len(ene_list[i]) < 3:\n",
    "        # Calculate the difference in length needed to make it 3\n",
    "        dff_len = 3 - len(ene_list[i])\n",
    "        # Create a truncated and padded cluster correlation energy list by adding zeros to meet the length of 3\n",
    "        trunc_ene_cc_list[i] = (ene_list[i] + [0] * dff_len)\n",
    "    else:\n",
    "        # If the cluster correlation energy list already has at least 3 values, keep all values\n",
    "        trunc_ene_cc_list[i] = ene_list[i]\n",
    "\n",
    "# Create a DataFrame 'df' using the truncated cluster correlation energy lists\n",
    "df = pd.DataFrame(trunc_ene_cc_list)\n",
    "\n",
    "# Calculate the difference between LCCSDT_DZTZ and LMP2_DZTZ energies and add it as a column 'deltacc_local'\n",
    "df['deltacc_local'] = df['LCCSDT_DZTZ'] - df['LMP2_DZTZ']\n",
    "\n",
    "# Calculate the difference between CCCSDT_TZQZ and CMP2_TZQZ energies and add it as a column 'deltacc'\n",
    "df['deltacc'] = df['CCCSDT_TZQZ'] - df['CMP2_TZQZ']\n",
    "\n",
    "# Reorder the columns of the DataFrame\n",
    "df = df[['LMP2_DZTZ', 'LCCSDT_DZTZ', 'deltacc_local', 'CMP2_TZQZ', 'CCCSDT_TZQZ', 'deltacc']]\n",
    "\n",
    "# Increment the index of the DataFrame by 1\n",
    "df.index += 1\n",
    "\n",
    "# Create a new DataFrame 'df1' with rounded integer values\n",
    "df1 = df.round().astype(int)\n",
    "\n",
    "# Calculate the average of the 'deltacc_local' column and assign it to 'ene_final' dictionary\n",
    "ene_final['Cluster CCSD(T)']['DeltaCC'] = [np.average(df['deltacc_local']), 3]\n",
    "\n",
    "# Print the DataFrame 'df1'\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all of the calculated data in the 'ene_final' dictionary\n",
    "ene_final['Cluster CCSD(T)']['Delta_geom']  = delta_geom\n",
    "ene_final['Cluster CCSD(T)']['Final'][0] = np.sum([ene_final['Cluster CCSD(T)'][x][0] for x in ['EMP2_Bulklimit','DeltaCC','Delta_geom']])\n",
    "ene_final['Cluster CCSD(T)']['Final'][1] = np.sqrt(np.sum([ene_final['Cluster CCSD(T)'][x][1]**2 for x in ['EMP2_Bulklimit','DeltaCC','Delta_geom']]))\n",
    "ene_final['Cluster CCSD(T)']['Cost'] = total_cputime\n",
    "ene_final['Cluster CCSD(T)']['RAM'] = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shixubenjamin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Schematic of the SKZCAM protocol process which we use in Fig 2 of the main text\n",
    "\n",
    "mp2_level = np.array(ene_list['MP2_TZQZ'])\n",
    "atom_size_list = np.array([6, 22, 34, 42, 58, 82, 84, 100, 108])\n",
    "cc_level = np.array(ene_list['LCCSDT_DZTZ'])\n",
    "\n",
    "gamma_best = find_co_gamma(ene_list['MP2_TZQZ'])\n",
    "slope, emp2_infty, r, p, se = linregress([1/(x**(gamma_best)) for x in tot_atom_list[:len(ene_list['MP2_TZQZ'])]],\\\n",
    "    [float(x) for x in ene_list['MP2_TZQZ']])\n",
    "\n",
    "x = np.linspace(0,150,2000)\n",
    "y = slope/(x**gamma_best) + emp2_infty\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(3.25,2),dpi=1200, constrained_layout=True)\n",
    "\n",
    "for side in ['right','top']:\n",
    "    axs.spines[side].set_visible(False)\n",
    "\n",
    "cc_start = 79\n",
    "cc_end = 1050\n",
    "\n",
    "axs.fill_between(x[cc_start:cc_end], y[cc_start:cc_end],y[cc_start:cc_end] + ene_final['Cluster CCSD(T)']['DeltaCC'][0],color=color_dict['yellow'],edgecolor=None,alpha=0.4)\n",
    "axs.plot(x[:cc_end],y[:cc_end],'--',linewidth=1,color=color_dict['blue'])\n",
    "axs.plot(x[cc_start:cc_end],y[cc_start:cc_end] + ene_final['Cluster CCSD(T)']['DeltaCC'][0] ,'--',linewidth=1,color='#d4af37')\n",
    "\n",
    "axs.scatter(atom_size_list[:len(mp2_level)], mp2_level, marker = 'x', linewidth=1,color=color_dict['blue'], label='Low-level MP2')\n",
    "axs.scatter(atom_size_list[:len(cc_level)], cc_level[:len(cc_level)], marker = 'o', color='#d4af37',facecolors='none', linewidth=1,label='High-level CCSD(T)')\n",
    "\n",
    "extra_spacing = 200\n",
    "\n",
    "axs.plot([85,110],[emp2_infty,emp2_infty],'-',linewidth=1,color=color_dict['blue'])\n",
    "axs.fill_between([85,110],[emp2_infty,emp2_infty],np.array([emp2_infty ,emp2_infty]) + ene_final['Cluster CCSD(T)']['DeltaCC'][0],color=color_dict['yellow'],edgecolor=None,alpha=0.4)\n",
    "\n",
    "axs.plot([85,110],np.array([emp2_infty ,emp2_infty]) + ene_final['Cluster CCSD(T)']['DeltaCC'][0] ,'-',linewidth=1,color='#d4af37')\n",
    "\n",
    "\n",
    "axs.legend(frameon=True,loc=(0.1,0.68),handletextpad=0.1)\n",
    "\n",
    "if usetex == True:\n",
    "    axs.set_ylabel(r'$E_\\textrm{int}$ (meV)')\n",
    "else:\n",
    "    axs.set_ylabel(r'Interaction energy (meV)')\n",
    "\n",
    "axs.set_xlabel(r'Cluster size (\\# of atoms)')\n",
    "\n",
    "\n",
    "axs.set_ylim([-220,-140])\n",
    "axs.set_xlim([0,100])\n",
    "\n",
    "plt.savefig('Figures/Fig_02.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tables8'></a>\n",
    "## Table S8 - Final periodic CCSD(T), periodic DMC and cluster CCSD(T) $E_\\textrm{ads}$ and their individual contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster CCSD(T)\n",
      "                Value  Error\n",
      "Final            -199     11\n",
      "EMP2_Bulklimit   -200      5\n",
      "DeltaCC            -7      3\n",
      "Delta_geom          8     10\n",
      "Cost               25      0\n",
      "RAM                40      0\n",
      "Periodic DMC\n",
      "                Value  Error\n",
      "Final            -188     26\n",
      "EDMC_2L          -159     14\n",
      "DeltaDMC_2L-4L     -9     19\n",
      "DeltaDMC_FSE      -33      5\n",
      "DeltaLDA_IPFSE      5      0\n",
      "Delta_geom          8     10\n",
      "Cost             1079      0\n",
      "RAM                 0      0\n",
      "Periodic CCSD(T)\n",
      "                Value  Error\n",
      "Final            -193     24\n",
      "ECCSD(T)_2L      -182     22\n",
      "DeltaMP2_2L-4L     -6      0\n",
      "DeltaMP2_core      -8      0\n",
      "DeltaHF_IPFSE      -5      0\n",
      "Delta_geom          8     10\n",
      "Cost              176      0\n",
      "RAM              3000      0\n",
      "                Value  Error\n",
      "Final            -193     24\n",
      "ECCSD(T)_2L      -182     22\n",
      "DeltaMP2_2L-4L     -6      0\n",
      "DeltaMP2_core      -8      0\n",
      "DeltaHF_IPFSE      -5      0\n",
      "Delta_geom          8     10\n",
      "Cost              176      0\n",
      "RAM              3000      0\n"
     ]
    }
   ],
   "source": [
    "# Compile all of the data in the previous sections to plot out Table S8 (which also contains all of the data in Table 1 of the main text)\n",
    "\n",
    "# We start with cluster CCSD(T), then periodic CCSD(T) and finally periodic DMC\n",
    "\n",
    "# Create a DataFrame 'df' using the 'ene_final' dictionary for Cluster CCSD(T) values\n",
    "df = pd.DataFrame(ene_final['Cluster CCSD(T)']).T\n",
    "\n",
    "# Rename the columns of the DataFrame 'df' as 'Value' and 'Error'\n",
    "df.columns = ['Value', 'Error']\n",
    "\n",
    "# Convert the computational 'Cost' value to kCPUhours (dividing by 1000). Set 'Error' for 'Cost' and 'RAM' to 0 as they are not applicable\n",
    "df['Value']['Cost'] = df['Value']['Cost'] / 1000\n",
    "df['Error']['Cost'] = 0\n",
    "df['Error']['RAM'] = 0\n",
    "\n",
    "# Round the values in the DataFrame 'df' and convert them to integers\n",
    "df = df.round().astype(int)\n",
    "\n",
    "# Print header and the DataFrame 'df' for Cluster CCSD(T) values\n",
    "print('Cluster CCSD(T)')\n",
    "print(df)\n",
    "\n",
    "# Create a DataFrame 'df1' using the 'ene_final' dictionary for Periodic DMC values\n",
    "df1 = pd.DataFrame(ene_final['Periodic DMC']).T\n",
    "\n",
    "# Rename the columns of the DataFrame 'df1' as 'Value' and 'Error'\n",
    "df1.columns = ['Value', 'Error']\n",
    "\n",
    "# Convert the 'Cost' value to kilojoules (dividing by 1000) and set 'Error' for 'Cost' and 'RAM' to 0\n",
    "df1['Value']['Cost'] = df1['Value']['Cost'] / 1000\n",
    "df1['Error']['Cost'] = 0\n",
    "df1['Error']['RAM'] = 0\n",
    "\n",
    "# Round the values in the DataFrame 'df1' and convert them to integers\n",
    "df1 = df1.round().astype(int)\n",
    "\n",
    "# Print header and the DataFrame 'df1' for Periodic DMC values\n",
    "print('Periodic DMC')\n",
    "print(df1)\n",
    "\n",
    "# Create a DataFrame 'df2' using the 'ene_final' dictionary for Periodic CCSD(T) values\n",
    "df2 = pd.DataFrame(ene_final['Periodic CCSD(T)']).T\n",
    "\n",
    "# Rename the columns of the DataFrame 'df2' as 'Value' and 'Error'\n",
    "df2.columns = ['Value', 'Error']\n",
    "\n",
    "# Calculate the (approximate) computational 'Cost' value for Periodic CCSD(T) and set 'Error' for 'Cost' and 'RAM' to 0\n",
    "df2['Value']['Cost'] = 2 * (80 + 6 + 2)\n",
    "df2['Error']['Cost'] = 0\n",
    "df2['Error']['RAM'] = 0\n",
    "\n",
    "# Round the values in the DataFrame 'df2' and convert them to integers\n",
    "df2 = df2.round().astype(int)\n",
    "\n",
    "# Print header and the DataFrame 'df2' for Periodic CCSD(T) values\n",
    "print('Periodic CCSD(T)')\n",
    "print(df2)\n",
    "\n",
    "# Save the 'ene_final' dictionary as a NumPy binary file 'methods_eads.npy'\n",
    "np.save('Data/Misc/methods_eads.npy', ene_final)\n",
    "\n",
    "# Print the DataFrame 'df2'\n",
    "print(df2)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tables12'></a>\n",
    "## Table S12 - Analysis of previous computational work on CO on MgO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged Eint for fifth cluster from SKZCAM protocol:              -196 meV\n",
      "Effect of smaller DZ basis set:                                     -122 meV <-- a weaker binding of 74 meV\n",
      "Effect of smaller TZ basis set:                                     -171 meV <-- a weaker binding of 25 meV\n",
      "Effect of smaller QZ basis set:                                     -184 meV <-- a weaker binding of 12 meV\n",
      "Effect of larger frozen core (2s and 2p electrons on Mg frozen):    -165 meV <-- a weaker binding of 31 meV\n",
      "Effect of not using counterpoise corrections:                       -294 meV <-- a stronger binding of 98 meV\n",
      "Effect of using a smaller 3x3x2 quantum cluster:                    -184 meV <-- a weaker binding of 12 meV\n"
     ]
    }
   ],
   "source": [
    "# The effect of using different unconverged settings on the interaction energy\n",
    "# Ideal interaction energy for the fifth rdf cluster.\n",
    "print('Converged Eint for fifth cluster from SKZCAM protocol:              {0:.0f} meV'.format(ene_list['MP2_DZTZ'][4]))\n",
    "\n",
    "# Effect of using a small basis set\n",
    "print('Effect of smaller DZ basis set:                                     {0:.0f} meV <-- a weaker binding of {1:.0f} meV'.format(ene_list['MP2_DZ'][4],ene_list['MP2_DZ'][4] - ene_list['MP2_DZTZ'][4]))\n",
    "print('Effect of smaller TZ basis set:                                     {0:.0f} meV <-- a weaker binding of {1:.0f} meV'.format(ene_list['MP2_TZ'][4],ene_list['MP2_TZ'][4] - ene_list['MP2_DZTZ'][4]))\n",
    "print('Effect of smaller QZ basis set:                                     {0:.0f} meV <-- a weaker binding of {1:.0f} meV'.format(ene_list['MP2_QZ'][4],ene_list['MP2_QZ'][4] - ene_list['MP2_DZTZ'][4]))\n",
    "\n",
    "# Large frozen core, which includes 2s and 2p electrons on the Mg atom\n",
    "print('Effect of larger frozen core (2s and 2p electrons on Mg frozen):    {0:.0f} meV <-- a weaker binding of {1:.0f} meV'.format(ene_list['MP2_DZTZ_lc'][4],ene_list['MP2_DZTZ_lc'][4] - ene_list['MP2_DZTZ'][4]))\n",
    "\n",
    "# No BSSE correction\n",
    "print('Effect of not using counterpoise corrections:                       {0:.0f} meV <-- a stronger binding of {1:.0f} meV'.format(ene_list['MP2_DZTZ_lc_NOCP'][4], np.abs(ene_list['MP2_DZTZ_lc_NOCP'][4] - ene_list['MP2_DZTZ'][4])))\n",
    "\n",
    "# Computing energy at the smaller cluster size\n",
    "ene_hf = []\n",
    "ene_mp2 = []\n",
    "for k in ['TZ','QZ']:\n",
    "    ene_hf += [get_eads('Data/MP2_Convergence/{0}/{1}'.format(0,k), code_format='mrcc',typ='hf')*Hartree*1000]\n",
    "    ene_mp2 += [get_eads('Data/MP2_Convergence/{0}/{1}'.format(0,k), code_format='mrcc',typ='lmp2_corr')*Hartree*1000]\n",
    "dummy = extrapolate.get_cbs(ene_hf[0],ene_mp2[0],ene_hf[1],ene_mp2[1],X=3,Y=4,family='mixcc',output=False)\n",
    "print('Effect of using a smaller 3x3x2 quantum cluster:                    {0:.0f} meV <-- a weaker binding of {1:.0f} meV'.format(dummy[-1],np.abs(ene_list['MP2_DZTZ'][4]  - dummy[-1] )))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frozen core</th>\n",
       "      <th>Basis set</th>\n",
       "      <th>BSSE</th>\n",
       "      <th>Cluster Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ugliengo et al.</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No (Mg9O9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Herschend et al.</th>\n",
       "      <td>No</td>\n",
       "      <td>No (TZ)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes (Mg18O18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qin et al.</th>\n",
       "      <td>No</td>\n",
       "      <td>No (DZ)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No (Mg9O9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Staemmler</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boese et al.</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li et al.</th>\n",
       "      <td>N/A</td>\n",
       "      <td>No [6-311+G(2df)]</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heuser et al.</th>\n",
       "      <td>N/A</td>\n",
       "      <td>No [TZ]</td>\n",
       "      <td>No</td>\n",
       "      <td>No (Mg9O9 without embedding)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mazheika and Levchenko</th>\n",
       "      <td>No</td>\n",
       "      <td>No [DZ and TZ]</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No (Mg9O9 with electrostatic embedding)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alessio et al.</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitra et al.</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No (TZ)</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Frozen core          Basis set BSSE  \\\n",
       "Ugliengo et al.                 No                Yes  Yes   \n",
       "Herschend et al.                No            No (TZ)  Yes   \n",
       "Qin et al.                      No            No (DZ)  Yes   \n",
       "Staemmler                      Yes                Yes  Yes   \n",
       "Boese et al.                   Yes                Yes  Yes   \n",
       "Li et al.                      N/A  No [6-311+G(2df)]  N/A   \n",
       "Heuser et al.                  N/A            No [TZ]   No   \n",
       "Mazheika and Levchenko          No     No [DZ and TZ]  Yes   \n",
       "Alessio et al.                 Yes                Yes  Yes   \n",
       "Mitra et al.                   Yes            No (TZ)   No   \n",
       "\n",
       "                                                   Cluster Size  \n",
       "Ugliengo et al.                                      No (Mg9O9)  \n",
       "Herschend et al.                                  Yes (Mg18O18)  \n",
       "Qin et al.                                           No (Mg9O9)  \n",
       "Staemmler                                                   Yes  \n",
       "Boese et al.                                                Yes  \n",
       "Li et al.                                                   Yes  \n",
       "Heuser et al.                      No (Mg9O9 without embedding)  \n",
       "Mazheika and Levchenko  No (Mg9O9 with electrostatic embedding)  \n",
       "Alessio et al.                                              Yes  \n",
       "Mitra et al.                                                Yes  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting Table S12 on understanding the convergence of previous computational work on the interaction energy of MgO(001)\n",
    "# This dictionary indicates whether either of the 4 settings are converged. It is not considered converged if their chosen settings are not within 10 meV of the fully converged settings of -199 meV.\n",
    "computational_work_convergence = {\n",
    "    'Ugliengo et al.': {\n",
    "        'Frozen core': 'No',\n",
    "        'Basis set': 'Yes',\n",
    "        'BSSE': 'Yes',\n",
    "        'Cluster Size': 'No (Mg9O9)'\n",
    "    },\n",
    "    'Herschend et al.': {\n",
    "        'Frozen core': 'No',\n",
    "        'Basis set': 'No (TZ)',\n",
    "        'BSSE': 'Yes',\n",
    "        'Cluster Size': 'Yes (Mg18O18)' \n",
    "    },\n",
    "    'Qin et al.': {\n",
    "        'Frozen core': 'No',\n",
    "        'Basis set': 'No (DZ)',\n",
    "        'BSSE': 'Yes',\n",
    "        'Cluster Size': 'No (Mg9O9)' \n",
    "    },\n",
    "    'Staemmler': {\n",
    "        'Frozen core': 'Yes',\n",
    "        'Basis set': 'Yes',\n",
    "        'BSSE': 'Yes',\n",
    "        'Cluster Size': 'Yes'\n",
    "    },\n",
    "    'Boese et al.': {\n",
    "        'Frozen core': 'Yes',\n",
    "        'Basis set': 'Yes',\n",
    "        'BSSE': 'Yes',\n",
    "        'Cluster Size': 'Yes'\n",
    "    },\n",
    "    'Li et al.': {\n",
    "        'Frozen core': 'N/A' ,\n",
    "        'Basis set': 'No [6-311+G(2df)]',\n",
    "        'BSSE': 'N/A',\n",
    "        'Cluster Size': 'Yes' \n",
    "    },\n",
    "    'Heuser et al.': {\n",
    "        'Frozen core': 'N/A' ,\n",
    "        'Basis set': 'No [TZ]',\n",
    "        'BSSE': 'No',\n",
    "        'Cluster Size': 'No (Mg9O9 without embedding)' \n",
    "    },\n",
    "    'Mazheika and Levchenko': {\n",
    "        'Frozen core': 'No' ,\n",
    "        'Basis set': 'No [DZ and TZ]',\n",
    "        'BSSE': 'Yes',\n",
    "        'Cluster Size': 'No (Mg9O9 with electrostatic embedding)' \n",
    "    },\n",
    "    'Alessio et al.': {\n",
    "        'Frozen core': 'Yes',\n",
    "        'Basis set': 'Yes',\n",
    "        'BSSE': 'Yes',\n",
    "        'Cluster Size': 'Yes'\n",
    "    },\n",
    "    'Mitra et al.': {\n",
    "        'Frozen core': 'Yes',\n",
    "        'Basis set': 'No (TZ)',\n",
    "        'BSSE': 'No',\n",
    "        'Cluster Size': 'Yes'\n",
    "    }\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(computational_work_convergence).T\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tables13'></a>\n",
    "## Table S13 - Computation of zero-point energy and thermal contribution terms to convert $H_\\textrm{ads}$ to $E_\\textrm{ads}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ZPE  Eth  RT  Ecor\n",
      "01_PBE-D2-Ne     31   -6   5    20\n",
      "02_revPBE-D4     28   -5   5    18\n",
      "03_vdW-DF        28   -5   5    17\n",
      "04_rev-vdW-DF2   32   -6   5    21\n",
      "05_PBE0-D4       30   -5   5    19\n",
      "06_B3LYP-D2-Ne   29   -5   5    18\n"
     ]
    }
   ],
   "source": [
    "# Compiling data for Table S13\n",
    "# Define a list 'params' with temperature and degrees of freedom values of the molecule\n",
    "params = [61, 1]  # [ Temperature, degrees of freedom = 3N-5 ] \n",
    "#Temperature given as average between studies by Dohnalek et al. and Wichtendahl et al.\n",
    "\n",
    "# Initialize a nested dictionary 'thermal_ene_contributions' to store various thermal energy contributions for the 6 studied DFT functional\n",
    "thermal_ene_contributions = {y: {x: 0 for x in dft_functionals} for y in ['ZPE', 'Eth', 'RT', 'Ecor']}\n",
    "\n",
    "# Iterate over each DFT functional\n",
    "for i in dft_functionals:\n",
    "    # Read vibrational frequencies from OUTCAR files\n",
    "    a, b = read_vib_freq('Data/DFT/Vib_Energy/{0}/AD_SLAB/OUTCAR'.format(i)) # CO on MgO\n",
    "    c, d = read_vib_freq('Data/DFT/Vib_Energy/{0}/AD/OUTCAR'.format(i)) # CO gas-phase molecule\n",
    "\n",
    "    # Calculate thermal and zero-point corrections as well as RT term for adsorbate and adsorbate on slab\n",
    "    ene_ad_slab, eth_ad_slab, zpe_ad_slab, kT = get_quasi_rrho(a, b, params[0])\n",
    "    ene_ad, eth_ad, zpe_ad, kT = get_quasi_rrho(c, d, params[0])\n",
    "\n",
    "    # Store thermal energy contributions in the nested dictionary 'thermal_ene_contributions'\n",
    "    thermal_ene_contributions['ZPE'][i] = zpe_ad_slab - zpe_ad\n",
    "    thermal_ene_contributions['Eth'][i] = eth_ad_slab - eth_ad\n",
    "    thermal_ene_contributions['Ecor'][i] = ene_ad_slab - ene_ad - kT\n",
    "    thermal_ene_contributions['RT'][i] = kT\n",
    "\n",
    "# Create a DataFrame 'df' using the 'thermal_ene_contributions' dictionary\n",
    "df = pd.DataFrame(thermal_ene_contributions)\n",
    "\n",
    "# Round the values in the DataFrame 'df' and convert them to integers\n",
    "df = df.round().astype(int)\n",
    "\n",
    "# Open a file 'thermal_corr.txt' in write mode\n",
    "f = open('Data/Misc/thermal_corr.txt', 'w')\n",
    "\n",
    "# Write average values of thermal energy contributions to the file\n",
    "f.write('{0} Ecor\\n'.format(np.average([thermal_ene_contributions['Ecor'][x] for x in thermal_ene_contributions['Ecor']])))\n",
    "f.write('{0} ZPE\\n'.format(np.average([thermal_ene_contributions['ZPE'][x] for x in thermal_ene_contributions['Ecor']])))\n",
    "f.write('{0} Eth\\n'.format(np.average([thermal_ene_contributions['Eth'][x] for x in thermal_ene_contributions['Ecor']])))\n",
    "f.write('{0} RT'.format(np.average([thermal_ene_contributions['RT'][x] for x in thermal_ene_contributions['Ecor']])))\n",
    "\n",
    "# Close the file 'thermal_corr.txt'\n",
    "f.close()\n",
    "\n",
    "# Calculate the average thermal correction and zero-point correction across the 6 functionals\n",
    "thermal_correction = np.average([thermal_ene_contributions['Ecor'][x] for x in thermal_ene_contributions['Ecor']])\n",
    "rt = np.average([thermal_ene_contributions['RT'][x] for x in thermal_ene_contributions['Ecor']])\n",
    "\n",
    "# Print the DataFrame 'df'\n",
    "print(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig3'></a>\n",
    "## Figure 3 and S1 - Converting previous experiment $H_\\textrm{ads}$ or $E_\\textrm{act}$ (for TPD) to $E_\\textrm{ads}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Figure 3 of the main text\n",
    "\n",
    "# Dictionary of Eact from the three TPD experiments\n",
    "experimental_eact = {\n",
    "    'Wichtendahl et al.': [-140,'Thermal programmed desorption',1999,'Eact, nu=13, low 0.3 ML coverage'],\n",
    "    'Dohnalek et al.': [-18.5*kjmol_to_meV,'Thermal programmed desorption',2001,'Eact, nu=15, dilute limit extrapolation'],\n",
    "    'Sterrer et al.': [-15*kjmol_to_meV,'Thermal programmed desorption',2006,'Eact, nu=13, high CO coverage']\n",
    "}\n",
    "\n",
    "# Dictionary of Eads from the three TPD experiments by adding the thermal correction and also the correction for pre-exponential factor.\n",
    "experimental_eads = {\n",
    "    'Wichtendahl et al.': [-16.9*kjmol_to_meV - thermal_correction,'Thermal programmed desorption',1999,'Campbell and Sellers, nu=13.8, low 0.3 ML coverage'],\n",
    "    'Dohnalek et al.': [-17.6*kjmol_to_meV - thermal_correction,'Thermal programmed desorption',2001,'Campbell and Sellers, nu=13.8, low 0.3 ML coverage'],\n",
    "    'Sterrer et al.': [-15*kjmol_to_meV + 0.5*rt - 0.8*2.3*rt - thermal_correction,'Thermal programmed desorption',2006,'nu=13.8 corrected, high CO coverage']\n",
    "}\n",
    "\n",
    "\n",
    "# Plot the figure\n",
    "fig, axs = plt.subplots(1,2,figsize=(7,2),dpi=1200,constrained_layout=True)\n",
    "\n",
    "\n",
    "axs[1].plot([ene_final['Cluster CCSD(T)']['Final'][0],ene_final['Cluster CCSD(T)']['Final'][0]],[1970,2025],'--',color='k',linewidth=1)\n",
    "axs[1].fill_betweenx([1970,2025],[ene_final['Cluster CCSD(T)']['Final'][0] - ene_final['Cluster CCSD(T)']['Final'][1],ene_final['Cluster CCSD(T)']['Final'][0] - ene_final['Cluster CCSD(T)']['Final'][1]],[ene_final['Cluster CCSD(T)']['Final'][0] + ene_final['Cluster CCSD(T)']['Final'][1],ene_final['Cluster CCSD(T)']['Final'][0] + ene_final['Cluster CCSD(T)']['Final'][1]],color=color_dict['grey'],linewidth=1,edgecolor='none',alpha=0.5)\n",
    "\n",
    "axs[1].scatter([experimental_eact['Wichtendahl et al.'][0],experimental_eact['Dohnalek et al.'][0],experimental_eact['Sterrer et al.'][0]],[1998,2000.5,2003],s=30, color=color_dict['blue'], marker='x',label=r'Original adsorption enthalpy $H_{ads}$')\n",
    "axs[1].errorbar([experimental_eads['Wichtendahl et al.'][0],experimental_eads['Dohnalek et al.'][0],experimental_eads['Sterrer et al.'][0]],[1998,2000.5,2003],xerr=1.6*2.3*rt,fmt='o',markersize=6,capsize=3,color=color_dict['orange'],markerfacecolor='none',label=r'Final adsorption energy $E_{ads}$')\n",
    "\n",
    "\n",
    "\n",
    "axs[1].set_xlabel(r'Binding energy (meV)')\n",
    "\n",
    "axs[1].spines['left'].set_visible(False)\n",
    "axs[1].spines['right'].set_visible(False)\n",
    "axs[1].spines['top']. set_visible(False)\n",
    "\n",
    "axs[1].set_ylim([2004.5,1997])\n",
    "axs[1].set_xlim([-100,-250])\n",
    "\n",
    "\n",
    "axs[1].xaxis.set_major_locator(MultipleLocator(50))\n",
    "axs[1].xaxis.set_minor_locator(MultipleLocator(25))\n",
    "\n",
    "axs[1].set_yticks([1998,2000.5,2003])\n",
    "axs[1].set_yticklabels([r'Wichtendahl et al.','Dohnalek et al.', 'Sterrer et al.'])\n",
    "\n",
    "\n",
    "\n",
    "axs[0].spines['left'].set_visible(False)\n",
    "axs[0].spines['bottom']. set_visible(False)\n",
    "axs[0].spines['right'].set_visible(False)\n",
    "axs[0].spines['top']. set_visible(False)\n",
    "axs[0].set_xticks([])\n",
    "axs[0].set_yticks([])\n",
    "\n",
    "\n",
    "axs[0].scatter([1998],[experimental_eact['Wichtendahl et al.'][0]],s=30, color=color_dict['blue'], marker='x')\n",
    "axs[0].errorbar([1998],[experimental_eads['Wichtendahl et al.'][0]],yerr=6,fmt='o',markersize=6,capsize=3,color=color_dict['orange'],markerfacecolor='none')\n",
    "axs[0].set_ylim([-250,-100])\n",
    "\n",
    "if usetex == False:\n",
    "    axs[1].set_ylim([2010,1990])\n",
    "    axs[1].legend(fontsize=7)\n",
    "\n",
    "plt.savefig('Figures/Fig_03.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Figure S1 of the main text\n",
    "\n",
    "# Dictionary of activation energy Eact from the three TPD experiments\n",
    "experimental_eact = {\n",
    "    'Wichtendahl et al.': [-140,'Thermal programmed desorption',1999,'Eact, nu=13, low 0.3 ML coverage'],\n",
    "    'Dohnalek et al.': [-18.5*kjmol_to_meV,'Thermal programmed desorption',2001,'Eact, nu=15, low 0.125 ML coverage'],\n",
    "    'Sterrer et al.': [-15*kjmol_to_meV,'Thermal programmed desorption',2006,'Eact, nu=13, high CO coverage']\n",
    "}\n",
    "# Dictionary of adsorption enthalpy Hads from the three TPD experiments and 2 FTIR experiments. Adsorption enthalpy of Wichtendahl et al. and Dohnalek et al. taken from Campbell and Sellers, which also corrected for the pre-exponential factor.\n",
    "experimental_hads = {\n",
    "    'Wichtendahl et al.': [-16.9*kjmol_to_meV,'Thermal programmed desorption',1999,'Campbell and Sellers, nu=13.8, low 0.3 ML coverage'],\n",
    "    'Dohnalek et al.': [-17.6*kjmol_to_meV,'Thermal programmed desorption',2001,'Campbell and Sellers, nu=13.8, low 0.3 ML coverage'],\n",
    "    'Spoto et al.1': [-11*kjmol_to_meV,'FTIR spectroscopy',2003,'MgO smoke'],\n",
    "    'Spoto et al.2': [-12.5*kjmol_to_meV,'FTIR spectroscopy',2004,'MgO smoke'],\n",
    "    'Sterrer et al.': [-15*kjmol_to_meV + 0.5*rt - 0.8*2.3*rt,'Thermal programmed desorption',2006,'nu=13.8 corrected, high CO coverage']\n",
    "}\n",
    "# Dictionary of adsorption energies\n",
    "experimental_eads = {\n",
    "    'Wichtendahl et al.': [-16.9*kjmol_to_meV - thermal_correction,'Thermal programmed desorption',1999,'Campbell and Sellers, nu=13.8, low 0.3 ML coverage'],\n",
    "    'Dohnalek et al.': [-17.6*kjmol_to_meV - thermal_correction,'Thermal programmed desorption',2001,'Campbell and Sellers, nu=13.8, low 0.3 ML coverage'],\n",
    "    'Spoto et al.1': [-11*kjmol_to_meV - thermal_correction,'FTIR spectroscopy',2003,'MgO smoke'],\n",
    "    'Spoto et al.2': [-12.5*kjmol_to_meV - thermal_correction,'FTIR spectroscopy',2004,'MgO smoke'],\n",
    "    'Sterrer et al.': [-15*kjmol_to_meV + 0.5*rt - 0.8*2.3*rt - thermal_correction,'Thermal programmed desorption',2006,'nu=13.8 corrected, high CO coverage']\n",
    "}\n",
    "\n",
    "# Plot the figure\n",
    "fig, axs = plt.subplots(figsize=(3.25,3),dpi=1200, sharey=True,constrained_layout=True)\n",
    "\n",
    "# The SKZCAM protocol reference number\n",
    "axs.plot([ene_final['Cluster CCSD(T)']['Final'][0],ene_final['Cluster CCSD(T)']['Final'][0]],[1970,2025],'--',color='k',linewidth=1)\n",
    "axs.fill_betweenx([1970,2025],[ene_final['Cluster CCSD(T)']['Final'][0] - ene_final['Cluster CCSD(T)']['Final'][1],ene_final['Cluster CCSD(T)']['Final'][0] - ene_final['Cluster CCSD(T)']['Final'][1]],[ene_final['Cluster CCSD(T)']['Final'][0] + ene_final['Cluster CCSD(T)']['Final'][1],ene_final['Cluster CCSD(T)']['Final'][0] + ene_final['Cluster CCSD(T)']['Final'][1]],color=color_dict['grey'],linewidth=1,edgecolor='none',alpha=0.5)\n",
    "\n",
    "axs.scatter([experimental_eact['Wichtendahl et al.'][0],experimental_eact['Dohnalek et al.'][0],experimental_eact['Sterrer et al.'][0]],[1997.5,2000,2002.5],s=30, color=color_dict['blue'], facecolor='none',label=r'Original adsorption enthalpy $H_{ads}$')\n",
    "axs.scatter([experimental_hads['Wichtendahl et al.'][0],experimental_hads['Dohnalek et al.'][0],experimental_hads['Sterrer et al.'][0]],[1998,2000.5,2003],s=30, color=color_dict['green'], facecolor='none',label=r'Re-analyzed $H_{ads}$') \n",
    "axs.scatter([experimental_eads['Wichtendahl et al.'][0],experimental_eads['Dohnalek et al.'][0],experimental_eads['Sterrer et al.'][0]],[1998.5,2001,2003.5],s=30, color=color_dict['orange'], facecolor='none',label=r'Final Adsorption energy') \n",
    "axs.errorbar([experimental_eads['Wichtendahl et al.'][0],experimental_eads['Dohnalek et al.'][0],experimental_eads['Sterrer et al.'][0]],[1998.5,2001,2003.5],xerr=1.6*2.3*rt,fmt='o',markersize=6,capsize=3,color=color_dict['orange'],markerfacecolor='none')\n",
    "\n",
    "\n",
    "\n",
    "axs.scatter([experimental_hads['Spoto et al.1'][0],experimental_hads['Spoto et al.2'][0]],[2006,2008],s=30, color=color_dict['green'], facecolor='none')\n",
    "axs.scatter([experimental_eads['Spoto et al.1'][0],experimental_eads['Spoto et al.2'][0]],[2006.5,2008.5],s=30, color=color_dict['orange'], facecolor='none')\n",
    "\n",
    "axs.set_xlabel(r'Binding energy (meV)')\n",
    "\n",
    "axs.spines['left'].set_visible(False)\n",
    "axs.spines['right'].set_visible(False)\n",
    "axs.spines['top']. set_visible(False)\n",
    "\n",
    "axs.set_ylim([2010,1995])\n",
    "axs.set_xlim([-100,-250])\n",
    "\n",
    "if usetex == False:\n",
    "    axs.set_ylim([2010,1990])\n",
    "    axs.legend(fontsize=7)\n",
    "\n",
    "\n",
    "axs.xaxis.set_major_locator(MultipleLocator(50))\n",
    "axs.xaxis.set_minor_locator(MultipleLocator(25))\n",
    "\n",
    "axs.set_yticks([1998,2000.5,2003,2006.75,2008.25])\n",
    "axs.set_yticklabels([r'Wichtendahl et al.','Dohnalek et al.','Sterrer et al.','Spoto et al.','Spoto et al.',])\n",
    "\n",
    "\n",
    "plt.savefig('Figures/Fig_S1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tables14'></a>\n",
    "## Table S14 - Final best estimate of TPD experimental adsorption energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference</th>\n",
       "      <th>Eads (meV)</th>\n",
       "      <th>CO Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wichtendahl et al.</td>\n",
       "      <td>-194</td>\n",
       "      <td>low 0.3 ML coverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dohnalek et al.</td>\n",
       "      <td>-201</td>\n",
       "      <td>low 0.3 ML coverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sterrer et al.</td>\n",
       "      <td>-181</td>\n",
       "      <td>high CO coverage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reference  Eads (meV)          CO Coverage\n",
       "0  Wichtendahl et al.        -194  low 0.3 ML coverage\n",
       "1     Dohnalek et al.        -201  low 0.3 ML coverage\n",
       "2      Sterrer et al.        -181     high CO coverage"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting Table S14 on the final TPD adsorption energies of the three experiments\n",
    "\n",
    "# Dictionary of adsorption energies and CO coverage\n",
    "experimental_eads = {\n",
    "    'Wichtendahl et al.': [-16.9*kjmol_to_meV - thermal_correction,'Thermal programmed desorption',1999,'low 0.3 ML coverage'],\n",
    "    'Dohnalek et al.': [-17.6*kjmol_to_meV - thermal_correction,'Thermal programmed desorption',2001,'low 0.3 ML coverage'],\n",
    "    'Sterrer et al.': [-15*kjmol_to_meV + 0.5*rt - 0.8*2.3*rt - thermal_correction,'Thermal programmed desorption',2006,'high CO coverage']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(experimental_eads).T\n",
    "df = df.reset_index()\n",
    "df.columns = ['Reference','Eads (meV)','Method','Year','CO Coverage']\n",
    "df = df[['Reference','Eads (meV)','CO Coverage']]\n",
    "df['Eads (meV)'] = [round(x) for x in df['Eads (meV)']]\n",
    "\n",
    "# Get best estimate as average of Wichtendahl et al. and Dohnalek et al.\n",
    "best_expt = np.average([experimental_eads['Wichtendahl et al.'][0],experimental_eads['Dohnalek et al.'][0]])\n",
    "\n",
    "# Plot table\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best experimental estimate: -198 +- 19 meV\n"
     ]
    }
   ],
   "source": [
    "# Best experimental estimate\n",
    "print(f\"Best experimental estimate: {round(best_expt)} +- {round(1.6*2.3*rt)} meV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tables15'></a>\n",
    "## Table S15 - Effect of CO coverage on $E_\\textrm{ads}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO coverage</th>\n",
       "      <th>Eads</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.125</th>\n",
       "      <td>0.250</td>\n",
       "      <td>-266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.250</th>\n",
       "      <td>0.125</td>\n",
       "      <td>-265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CO coverage  Eads  Diff\n",
       "0.125       0.250  -266     0\n",
       "0.250       0.125  -265     1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting Table S15 for effect of CO coverage on adsorption energy\n",
    "\n",
    "# Initialize a nested dictionary 'eads_dft_coverage' to store adsorption energy values for different CO coverages\n",
    "eads_dft_coverage_conv = {\n",
    "    '0.125': {\n",
    "        # 'Supercell Size': '4x4' ,\n",
    "        'CO coverage': '0.250' ,\n",
    "        'Eads': 0,\n",
    "        'Diff': 0\n",
    "    },\n",
    "    '0.250': {\n",
    "        # 'Supercell Size': '2x2' ,\n",
    "        'CO coverage': '0.125' ,\n",
    "        'Eads': 0,\n",
    "        'Diff': 0\n",
    "    },\n",
    "}\n",
    "\n",
    "# Iterate over each CO coverage and get adsorption energy\n",
    "for i in ['0.125','0.250']:\n",
    "    ad_slab = find_energy('Data/DFT/Convergence/Coverage/{0}/AD_SLAB/OUTCAR'.format(i),code_format='vasp')\n",
    "    ad =  find_energy('Data/DFT/Convergence/Coverage/{0}/AD/OUTCAR'.format(i),code_format='vasp')\n",
    "    slab = find_energy('Data/DFT/Convergence/Coverage/{0}/SLAB/OUTCAR'.format(i),code_format='vasp')\n",
    "\n",
    "    eads = (ad_slab-ad-slab)*1000\n",
    "    if i == '0.125':\n",
    "        eads0 = eads\n",
    "    \n",
    "    eads_dft_coverage_conv[i]['Eads'] = eads\n",
    "    eads_dft_coverage_conv[i]['Diff'] = (eads - eads0)\n",
    "\n",
    "df = pd.DataFrame(eads_dft_coverage_conv).T\n",
    "df['Eads'] = df['Eads'].apply(lambda x: round(x))\n",
    "df['Diff'] = df['Diff'].apply(lambda x: round(x))\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
